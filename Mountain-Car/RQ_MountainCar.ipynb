{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\Desktop\\vs_git\\.virtualenvs\\venv\\lib\\site-packages\\ale_py\\roms\\utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for external in metadata.entry_points().get(self.group, []):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\Desktop\\vs_git\\.virtualenvs\\venv\\lib\\site-packages\\stable_baselines\\__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "import numpy as np\n",
    "from stable_baselines import DQN\n",
    "from copy import deepcopy\n",
    "import math\n",
    "from gym.spaces import Discrete, Dict, Box\n",
    "from gym import spaces\n",
    "from random import seed\n",
    "import random \n",
    "from gym import Env\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import stable_baselines\n",
    "import sklearn\n",
    "import numpy\n",
    "from sklearn import tree , svm \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB , CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import product\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold , RepeatedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import impute\n",
    "import statistics\n",
    "from scipy import stats\n",
    "from copy import deepcopy\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from math import ceil\n",
    "import copy\n",
    "import sys\n",
    "from sklearn.metrics import jaccard_score\n",
    "import time\n",
    "import multiprocessing\n",
    "from pymoo.algorithms.nsga2 import calc_crowding_distance\n",
    "sys.path.append('lib/')\n",
    "import subprocess\n",
    "import logging\n",
    "from sklearn.utils import shuffle\n",
    "import csv\n",
    "from csv import reader\n",
    "import os\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StoreAndTerminateWrapper(gym.Wrapper):\n",
    "  ''''\n",
    "  :param env: (gym.Env) Gym environment that will be wrapped\n",
    "  :param max_steps: (int) Max number of steps per episode\n",
    "  '''\n",
    "  def __init__(self, env):\n",
    "    # Call the parent constructor, so we can access self.env later\n",
    "    super(StoreAndTerminateWrapper, self).__init__(env)\n",
    "    self.max_steps = 200\n",
    "    # Counter of steps per episode\n",
    "    self.current_step = 0\n",
    "    self.mem = []\n",
    "    self.TotalReward = 0.0 \n",
    "    self.env = env\n",
    "    self.first_state = 0\n",
    "    self.first_obs = 0\n",
    "    self.prev_obs = 0 \n",
    "    self.states_list = []\n",
    "    self.info = {}\n",
    "  \n",
    "  def reset(self):\n",
    "    \"\"\"\n",
    "    Reset the environment \n",
    "    \"\"\"\n",
    "    # Reset the counter\n",
    "    self.current_step = 0\n",
    "    obs =self.env.reset()\n",
    "    self.TotalReward = 0.0\n",
    "    self.first_obs = obs\n",
    "    return obs\n",
    "\n",
    "  def step(self, action):\n",
    "    \"\"\"\n",
    "    In this function we store the initial state as well as the memory of the agent\n",
    "    :param action: ([float] or int) Action taken by the agent\n",
    "    :return: (np.ndarray, float, bool, dict) observation, reward, is the episode over?, additional informations\n",
    "    \"\"\"\n",
    "    if self.current_step == 0: #store initial state\n",
    "      self.prev_obs = self.first_obs\n",
    "      self.first_state = deepcopy(self.env)\n",
    "      self.states_list.append(self.first_state)\n",
    "    # print(\"t\",self.env.state[0],\"reward\",self.TotalReward)\n",
    "    # if self.env.state[0]==-1.2:\n",
    "    #   print(\"-1.2\")\n",
    "    #   obs = self.reset()\n",
    "    #   reward = -200\n",
    "    #   done = True\n",
    "    #   return obs, reward, done, False\n",
    "    self.current_step += 1\n",
    "    obs, reward, done, info = self.env.step(action)\n",
    "    self.TotalReward += reward\n",
    "    self.mem.append(tuple((self.prev_obs,action)))\n",
    "    self.prev_obs = obs\n",
    "    if self.current_step >= self.max_steps:\n",
    "      done = True\n",
    "      # Update the info dict to signal that the limit was exceeded\n",
    "    if obs[0]<=-1.2:\n",
    "      done = True\n",
    "      reward = -201 - self.TotalReward\n",
    "      self.TotalReward =-200\n",
    "      # print(\"fff\",reward)\n",
    "    if done:\n",
    "      self.mem.append(tuple(('done',self.TotalReward)))\n",
    "    self.info['mem'] = self.mem\n",
    "    self.info['state'] = self.states_list\n",
    "    # self.mem.append(tuple(obs,action))\n",
    "    return obs, reward, done, info\n",
    "\n",
    "  def set_state(self, state):\n",
    "    \"\"\"\n",
    "    :param state: initial state of the episode\n",
    "    :return: environment is updated and observations is returned\n",
    "    \"\"\"\n",
    "    self.env = deepcopy(state)\n",
    "    obs = np.array(list(self.env.unwrapped.state))\n",
    "    self.current_step = 0\n",
    "    self.TotalReward = 0.0\n",
    "    self.first_obs = obs\n",
    "    return obs\n",
    "\n",
    "\n",
    "def abstract_state_general(model,state1,d):\n",
    "  if type(state1) == str:\n",
    "    if state1 == 'done':\n",
    "      return 'end'\n",
    "  q_values = model.step_model.step([state1])\n",
    "  return tuple([ceil(q_value/d) for q_value in q_values[1][0]])\n",
    "\n",
    "def Abstract_classes(ep,abstraction_d,model):\n",
    "  d=abstraction_d\n",
    "  abs_states1=[]\n",
    "  for episode in ep:\n",
    "    for state,action in episode:\n",
    "      abs_st = abstract_state_general(model,state,d)\n",
    "      if abs_st == 'end':\n",
    "        continue\n",
    "      abs_states1.append(abs_st)\n",
    "  unique1=list(set(abs_states1))\n",
    "  uni1 = np.array(unique1)\n",
    "  a=len(abs_states1)\n",
    "  b=len(set(abs_states1))\n",
    "  print(\"abstract states:\",b)\n",
    "  print(\"Concrete states\",a)\n",
    "  print(\"ratio\",b/a)\n",
    "  return unique1,uni1\n",
    "\n",
    "def ML_first_representation_func_based(Abs_d,functional_func,reward_func,model,input_episodes,unique1):\n",
    "  \"\"\"\n",
    "  TO-DO : fix epsilon and threshold\n",
    "  \"\"\"\n",
    "  d = Abs_d\n",
    "  data1_x_b=[]\n",
    "  data1_y_b= [] \n",
    "  data1_y_f_b = []\n",
    "  for i, episode in enumerate(input_episodes):\n",
    "    record = np.zeros(len(unique1))\n",
    "    temp_flag = False\n",
    "    for state, action in episode:\n",
    "      ab = abstract_state_general(model,state,d)\n",
    "      if ab == 'end':\n",
    "        assert not temp_flag, f'Episode data problem, two terminations in one episode. Episode number{i}'\n",
    "        temp_flag = True\n",
    "        # print(action)\n",
    "        # print(functional_func(episode))\n",
    "        if functional_func(episode):\n",
    "          data1_y_f_b.append(1)\n",
    "        else:\n",
    "          data1_y_f_b.append(0)\n",
    "        if reward_func(episode):\n",
    "          data1_y_b.append(1)\n",
    "        else:\n",
    "          data1_y_b.append(0)\n",
    "        # print(\"end\\n\\n\\n\")\n",
    "        # print(len(data1_y_b),\"len(input_episodes)\",len(input_episodes))\n",
    "        continue\n",
    "        # print(state[0])\n",
    "      ind = unique1.index(ab)\n",
    "      record[ind] = 1\n",
    "      # print(state, action)\n",
    "      assert len(data1_y_b)<len(input_episodes), \"assert\"\n",
    "      # if you want the frequency go with the next line \n",
    "      # record[ind] += 1\n",
    "    data1_x_b.append(record)\n",
    "\n",
    "  return data1_x_b, data1_y_b, data1_y_f_b\n",
    "\n",
    "def report(model2,x_train, y_train,x_test, y_test):\n",
    "  print(\"********************** reporting the result of the model **************************\")\n",
    "  print('The score for train data is {0}'.format(model2.score(x_train,y_train)))\n",
    "  print('The score for test data is {0}'.format(model2.score(x_test,y_test)))\n",
    "\n",
    "\n",
    "  predictions_train = model2.predict(x_train)\n",
    "  predictions_test = model2.predict(x_test)\n",
    "\n",
    "  print(\"\\n\\n--------------------------------------recall---------------------------------\")\n",
    "\n",
    "  print('the test recall for the class yes is {0}'.format(metrics.recall_score(y_test,predictions_test, pos_label=1)))\n",
    "  print('the test recall for the class no is {0}'.format(metrics.recall_score(y_test,predictions_test, pos_label=0)))\n",
    "\n",
    "  print('the training recall for the class yes is {0}'.format(metrics.recall_score(y_train,predictions_train, pos_label=1)))\n",
    "  print('the training recall for the class no is {0}'.format(metrics.recall_score(y_train,predictions_train, pos_label=0)))\n",
    "\n",
    "\n",
    "  print(\"\\n\\n--------------------------------------precision------------------------------\")\n",
    "\n",
    "\n",
    "  print('the test precision for the class yes is {0}'.format(metrics.precision_score(y_test,predictions_test, pos_label=1)))\n",
    "  print('the test precision for the class no is {0}'.format(metrics.precision_score(y_test,predictions_test, pos_label=0)))\n",
    "\n",
    "  print('the training precision for the class yes is {0}'.format(metrics.precision_score(y_train,predictions_train, pos_label=1)))\n",
    "  print('the training precision for the class no is {0}'.format(metrics.precision_score(y_train,predictions_train, pos_label=0)))\n",
    "\n",
    "  print(\"\\n\\n\")\n",
    "  print(classification_report(y_test, predictions_test, target_names=['NO ','yes']))\n",
    "\n",
    "  tn, fp, fn, tp = confusion_matrix(y_test, predictions_test).ravel()\n",
    "  specificity = tn / (tn+fp)\n",
    "  print(\"\\n\\nspecifity :\",specificity)\n",
    "  print(\"\\n\\n--------------------------------------confusion----------------------------\")\n",
    "  CM = metrics.confusion_matrix(y_test, predictions_test)\n",
    "  print(\"The confusion Matrix:\")\n",
    "  print(CM)\n",
    "  print('the accuracy score in {0}\\n\\n'.format(accuracy_score(y_test, predictions_test)))\n",
    "  print(\"********************** plotting the confusion matrix & ROC curve **************************\")\n",
    "  plot_confusion_matrix(model2, x_test, y_test)\n",
    "  metrics.plot_roc_curve(model2, x_test, y_test) \n",
    "  plt.show()\n",
    "\n",
    "# write function for load\n",
    "\n",
    "\n",
    "def random_test_2(model, env, Num):\n",
    "  # start= len(info['mem'])\n",
    "  obs=env.reset()\n",
    "  counter = 1\n",
    "  episode_reward = 0.0\n",
    "  for i in range(Num):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "    if done:\n",
    "      counter += 1\n",
    "      end = i\n",
    "      episode_reward = 0.0\n",
    "      obs = env.reset()\n",
    "  iter = deepcopy(counter)\n",
    "  u=1\n",
    "  while iter>1:\n",
    "    if env.info['mem'][-u][0]=='done':\n",
    "      lastpoint = -u\n",
    "      iter -= 1\n",
    "    u+=1\n",
    "  fin =Num - end\n",
    "  start = -Num -counter\n",
    "  randomtest = env.info['mem'][lastpoint:-fin]\n",
    "  ran_state = env.info['state'][(-counter+1):-1]\n",
    "  return randomtest , ran_state\n",
    "\n",
    "def fix_testing(testing_episodes,testing_states,Env2):\n",
    "  buffer =[] \n",
    "  episodes_set = []\n",
    "  j=0\n",
    "  for i in range(len(testing_episodes)):\n",
    "    if testing_episodes[i][0] == 'done':\n",
    "      if i == 0:\n",
    "        continue\n",
    "      buffer.append(testing_episodes[i])\n",
    "      episodes_set.append(buffer)\n",
    "      buffer=[]\n",
    "    else:\n",
    "      buffer.append(testing_episodes[i])\n",
    "      # np.array(mtc_wrapped.set_state(qq[0]),dtype=\"float32\")\n",
    "  if not (episodes_set[0][0][0]==np.array(Env2.set_state(testing_states[0]),dtype=\"float32\")).all():\n",
    "    del testing_states[0]\n",
    "  if not (episodes_set[0][0][0]==np.array(Env2.set_state(testing_states[0]),dtype=\"float32\")).all():\n",
    "    assert False, 'problem in starting states'\n",
    "  if len(episodes_set)!=len(testing_states):\n",
    "    del testing_states[-1]\n",
    "  if len(episodes_set)!=len(testing_states):\n",
    "    assert False, 'problem in data prepration'\n",
    "  return episodes_set , testing_states\n",
    "\n",
    "def is_functional_fault(episode):\n",
    "  epsilon = 0.1\n",
    "  env = mtc_wrapped\n",
    "  reward = episode[-1][1]\n",
    "  last_state = episode[-2][0][0]\n",
    "  if last_state<(env.low[0]+epsilon) and reward == -200:\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_reward_fault(episode):\n",
    "  RF_threshold = -180\n",
    "  reward = episode[-1][1]\n",
    "  # print(len(episode))\n",
    "  if reward<RF_threshold and len(episode)>200:\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_functional_fault_last_state(last_step,done_step):\n",
    "  epsilon = 0.1\n",
    "  env = mtc_wrapped\n",
    "  assert done_step[0]=='done', \"Wrong input!\"\n",
    "  reward = done_step[1]\n",
    "  last_state = last_step[0][0]\n",
    "  if last_state<(env.low[0]+epsilon) and reward == -200:\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_reward_fault_last_state(last_step,done_step):\n",
    "  RF_threshold = -180\n",
    "  assert done_step[0]=='done', \"Wrong input!\"\n",
    "  reward = done_step[1]\n",
    "  last_state = last_step[0][0]\n",
    "  # print(len(episode))\n",
    "  if reward<RF_threshold and not is_functional_fault_last_state(last_step,done_step):\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def load_p(name):\n",
    "  with open(f'/content/drive/MyDrive/MC/{name}.pickle', 'rb') as file2:\n",
    "    to_what = pickle.load(file2)\n",
    "  return to_what\n",
    "def local_load_p(name):\n",
    "  with open(f'c:/Users/Student/Desktop/Data/{name}', 'rb') as file2:\n",
    "    to_what = pickle.load(file2)\n",
    "  return to_what\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(episode,model, d, unique5):\n",
    "  \"\"\"\n",
    "  thid function takes the concrete episodes and returns the encoded episodes \n",
    "  based on the presence and absence of the individuals  \n",
    "  :param 'episode': input episode\n",
    "  :param 'model': RL model\n",
    "  :param 'd': abstraction level = 1\n",
    "  :param 'unique5': abstract classes \n",
    "  :return: encoded episodse based on the presence and absence\n",
    "\n",
    "  \"\"\"\n",
    "  d=d\n",
    "  record = np.zeros(len(unique5))\n",
    "  for state, action in episode:\n",
    "    ab = abstract_state_general(model,state,d)\n",
    "    if ab == 'end':\n",
    "      continue\n",
    "    if ab in unique5:\n",
    "      ind = unique5.index(ab)\n",
    "      record[ind] = 1\n",
    "  return [record]\n",
    "\n",
    "def episode_player(episodes,d, abs_classes, model, monitor) -> list:\n",
    "  ''' This function replays the episodes and returns the risk of each step in each episode\n",
    "  :param 'episodes': input episodes\n",
    "  :param 'd': abstraction level \n",
    "  :param 'abs_classes': abstract classes\n",
    "  :param 'model': RL model\n",
    "  :param 'monitor': ML model\n",
    "  :return: risk of each step in each episode\n",
    "  \n",
    "  '''\n",
    "  episodes_risk=[]\n",
    "  for episode in episodes:\n",
    "    risk_array=[]\n",
    "    for step in range(len(episode)-1):\n",
    "      monitoring_data = translator(episode[:step],model,d,abs_classes)\n",
    "      Risk = monitor.predict_proba(monitoring_data)\n",
    "      risk_array.append(Risk[0][1])\n",
    "    episodes_risk.append(risk_array)\n",
    "  return episodes_risk\n",
    "\n",
    "def single_episode_player(episode,d, abs_classes, model, monitor) -> list:\n",
    "  ''' This function replays one episodes and returns the risk of each step in episode\n",
    "  :param 'episode': input episode\n",
    "  :param 'd': abstraction level\n",
    "  :param 'abs_classes': abstract classes\n",
    "  :param 'model': RL model\n",
    "  :param 'monitor': ML model\n",
    "  :return: risk of each step in episode\n",
    "  '''\n",
    "  risk_array=[]\n",
    "  for step in range(len(episode)-1):\n",
    "    monitoring_data = translator(episode[:step],model,d,abs_classes)\n",
    "    Risk = monitor.predict_proba(monitoring_data)\n",
    "    risk_array.append(Risk[0][1])\n",
    "  return risk_array\n",
    "\n",
    "def line_plot(data):\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    for i in range(len(data)): \n",
    "        plt.plot( [i for i in range(len(data[i]))], data[i], label = f\"Episode {i}\")\n",
    "    # plt.plot(y, x, label = \"line 2\")\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_positions(episodes):\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    \n",
    "    for i in range(len(episodes)):\n",
    "        position =[]\n",
    "        position_arr =[]\n",
    "        for j in range(len(episodes[i])-1):\n",
    "            position.append(episodes[i][j][0][0])\n",
    "        position_arr.append(position)\n",
    "        plt.plot([i for i in range(len(position))], position, label = f\"Episode {i}\")\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_velocity(episodes):\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    \n",
    "    for i in range(len(episodes)):\n",
    "        velocity =[]\n",
    "        velocity_arr =[]\n",
    "        for j in range(len(episodes[i])-1):\n",
    "            velocity.append(episodes[i][j][0][1])\n",
    "        velocity_arr.append(velocity)\n",
    "        plt.plot([i for i in range(len(velocity))], velocity, label = f\"Episode {i}\")\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def position_extractor(episode):\n",
    "    position =[]\n",
    "    for i in range(len(episode)-1):\n",
    "        position.append(episode[i][0][0])\n",
    "    return position\n",
    "    \n",
    "def velocity_extractor(episode):\n",
    "    velocity =[]\n",
    "    for i in range(len(episode)-1):\n",
    "        velocity.append(episode[i][0][1])\n",
    "    return velocity\n",
    "\n",
    "\n",
    "def Plot_all(data,save=False,show=True,data_chunk=0,path='Plots/v2'):\n",
    "    '''plot risk and position snd velocity in one figure with 3 subplots\n",
    "    '''\n",
    "    fig, axs = plt.subplots(3,figsize=(20, 18))\n",
    "    for i in range(len(data)):\n",
    "        axs[0].plot([i for i in range(len(data[i])-1)], single_episode_player(data[i],d,unique1,model,RF_FF_1rep), label = f\"Episode {i}\")\n",
    "        axs[1].plot([i for i in range(len(data[i])-1)], position_extractor(data[i]), label = f\"Episode {i}\")\n",
    "        axs[2].plot([i for i in range(len(data[i])-1)], velocity_extractor(data[i]), label = f\"Episode {i}\")\n",
    "    axs[0].legend()\n",
    "    axs[1].legend()\n",
    "    axs[2].legend()\n",
    "    current_time = datetime.now()\n",
    "    ID = current_time.strftime(\"%Y%m%d%H%M%S\")\n",
    "    if save:\n",
    "        fig.savefig(f'{path}/RPV_C{data_chunk}_{ID}.png')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def translate_episode_steps(episode,RL_model,translator,d,abs_classes):\n",
    "    translated_episode = []\n",
    "    for i in range(len(episode)-1):\n",
    "        translated_episode.append(translator(episode[:i],RL_model,d,abs_classes))\n",
    "    return translated_episode\n",
    "\n",
    "def translate_multiple_episodes_steps(episodes,RL_model,translator,d,abs_classes):\n",
    "    translated_episodes = []\n",
    "    for n, episode in enumerate(episodes):\n",
    "        translated_buffer = []\n",
    "        for i in tqdm(range(len(episode)-1),desc=f'translating episode {n}'):\n",
    "            translated_buffer.append(translator(episode[:i],RL_model,d,abs_classes))\n",
    "        translated_episodes.append(translated_buffer)\n",
    "    return translated_episodes\n",
    "\n",
    "\n",
    "def translate_multiple_episodes_steps_tqdm(episodes,RL_model,translator,d,abs_classes):\n",
    "    translated_episodes = []\n",
    "    for episode in tqdm(episodes,desc=f'translating episodes'):\n",
    "        translated_buffer = []\n",
    "        for i in range(len(episode)-1):\n",
    "            translated_buffer.append(translator(episode[:i],RL_model,d,abs_classes))\n",
    "        translated_episodes.append(translated_buffer)\n",
    "    return translated_episodes\n",
    "\n",
    "\n",
    "def Forest_CI_multiple(translated_episodes,HD_model,chunk,abs_d,path = 'C:/Users/Student/Desktop/vs_git/HazardDetection/Plots/CI'):\n",
    "    '''\n",
    "    size of translated_episodes is limited by the number of colors available for one plot\n",
    "    '''\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    results_Arr=[]\n",
    "    r_arr=[]\n",
    "    E=0\n",
    "    colors = ['red','blue','green','yellow','black','purple','orange','pink','brown','grey','cyan','magenta','lime','olive','teal','navy','maroon','violet','turquoise','salmon','gold','coral','indigo','crimson','azure','beige','chocolate','lavender','plum','orchid','tan','khaki','wheat','silver','sienna','peru','peachpuff','papayawhip','mistyrose','moccasin','lemonchiffon','lawngreen','lightgreen','limegreen']\n",
    "    for translated_episode , plt_color in zip(translated_episodes,colors[:len(translated_episodes)]):\n",
    "        E+=1\n",
    "        num_time_steps = len(translated_episode) # Number of time steps\n",
    "        num_trees = HD_model.n_estimators\n",
    "        predictions = np.zeros((num_time_steps, num_trees))\n",
    "        for i, tree in enumerate(HD_model.estimators_):\n",
    "            for j in range(len(translated_episode)):\n",
    "                Risk = tree.predict_proba(translated_episode[j])[0][1]\n",
    "                predictions[j, i] = Risk\n",
    "        # Calculate the mean prediction for each time step\n",
    "        mean_predictions = np.mean(predictions, axis=1)\n",
    "\n",
    "        # Calculate the standard deviation for each time step\n",
    "        std_predictions = np.std(predictions, axis=1)\n",
    "\n",
    "        # Calculate the lower and upper bounds for the confidence intervals\n",
    "        confidence_level = 0.95 # Change as needed\n",
    "        z_score = scipy.stats.norm.ppf((1 + confidence_level) / 2)\n",
    "        lower_bounds = mean_predictions - z_score * std_predictions / np.sqrt(num_trees)\n",
    "        upper_bounds = mean_predictions + z_score * std_predictions / np.sqrt(num_trees)\n",
    "        difference = upper_bounds - lower_bounds\n",
    "        # Store the results in a dataframe\n",
    "        results = pd.DataFrame({\n",
    "            'Mean prediction': mean_predictions,\n",
    "            'Lower bound': lower_bounds,\n",
    "            'Upper bound': upper_bounds\n",
    "        })\n",
    "        # Save the results to a file\n",
    "        results_Arr.append(results)\n",
    "        r_arr.append([mean_predictions, lower_bounds, upper_bounds,difference])\n",
    "        plt.fill_between(range(num_time_steps), lower_bounds, upper_bounds, color=plt_color, alpha=0.2)\n",
    "        plt.plot(mean_predictions, color=plt_color, label=f'Episode {E}')\n",
    "\n",
    "        # Add labels and title to the plot\n",
    "        plt.xlabel('Time step')\n",
    "        plt.ylabel('Prediction')\n",
    "        plt.title('Confidence Intervals of Random Forest Predictions')\n",
    "    # results_arr.append(r_arr)\n",
    "    # Save the plot as a file\n",
    "    current_time = datetime.now()\n",
    "    ID = current_time.strftime(\"%Y%m%d%H%M%S\")\n",
    "    # if save:\n",
    "    #     fig.savefig(f'{path}/RPV_C{data_chunk}_{ID}.png')\n",
    "    # plt.savefig(f'C:/Users/Student/Desktop/vs_git/HazardDetection/Plots/CI/abs_{d}/confidence_intervals_{chunk}_{ID}.png', bbox_inches='tight')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{path}/confidence_intervals_{chunk}_{ID}.png', bbox_inches='tight')\n",
    "    # np.array(results_Arr).to_csv('confidence_intervals.csv', index=False)\n",
    "    # save results_arr to pickle file\n",
    "    pickle_path = f'C:/Users/Student/Desktop/vs_git/HazardDetection/Data/CI/Abs_{abs_d}'\n",
    "    if not os.path.exists(pickle_path):\n",
    "        os.makedirs(pickle_path)\n",
    "    with open(f'{pickle_path}/results_arr_{chunk}.pkl', 'wb') as f:\n",
    "        pickle.dump(r_arr, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACCu(translated_episodes,HD_model,chunk,abs_d,path='Data/Pred'):\n",
    "    '''\n",
    "    size of translated_episodes is limited by the number of colors available for one plot\n",
    "    '''\n",
    "    # plt.figure(figsize=(20, 12))\n",
    "    results_Arr=[]\n",
    "    r_arr=[]\n",
    "    E=0\n",
    "    RF_pred=[]\n",
    "    # translated_episodes = translate_multiple_episodes_steps(episode,RL_model,translator,d,unique1)\n",
    "    # colors = ['red','blue','green','yellow','black','purple','orange','pink','brown','grey','cyan','magenta','lime','olive'\\\n",
    "    # ,'teal','navy','maroon','violet','turquoise','salmon','gold','coral','indigo','crimson','azure','beige','chocolate',\\\n",
    "    # 'lavender','plum','orchid','tan','khaki','wheat','silver','sienna','peru','peachpuff','papayawhip','mistyrose','moccasin','lemonchiffon','lawngreen','lightgreen','limegreen']\n",
    "    for k, translated_episode in enumerate(translated_episodes):\n",
    "        RF_pred_E=[]\n",
    "        E+=1\n",
    "        num_time_steps = len(translated_episode) # Number of time steps\n",
    "        num_trees = HD_model.n_estimators\n",
    "        predictions = np.zeros((num_time_steps, num_trees))\n",
    "        for j in tqdm(range(len(translated_episode)),desc=f'extracting risk for episode {k}'):\n",
    "            RF_pred_E.append(HD_model.predict_proba(translated_episode[j])[0][1])\n",
    "            for i, tree in enumerate(HD_model.estimators_):\n",
    "                Risk = tree.predict_proba(translated_episode[j])[0][1]\n",
    "                predictions[j, i] = Risk\n",
    "        # Calculate the mean prediction for each time step\n",
    "        mean_predictions = np.mean(predictions, axis=1)\n",
    "            \n",
    "        # Calculate the standard deviation for each time step\n",
    "        std_predictions = np.std(predictions, axis=1)\n",
    "\n",
    "        # Calculate the lower and upper bounds for the confidence intervals\n",
    "        confidence_level = 0.95 # Change as needed\n",
    "        z_score = scipy.stats.norm.ppf((1 + confidence_level) / 2)\n",
    "        lower_bounds = mean_predictions - z_score * std_predictions / np.sqrt(num_trees)\n",
    "        upper_bounds = mean_predictions + z_score * std_predictions / np.sqrt(num_trees)\n",
    "        difference = upper_bounds - lower_bounds\n",
    "        # Store the results in a dataframe\n",
    "        results = pd.DataFrame({\n",
    "            'Mean prediction': mean_predictions,\n",
    "            'Lower bound': lower_bounds,\n",
    "            'Upper bound': upper_bounds\n",
    "        })\n",
    "        # Save the results to a file\n",
    "        results_Arr.append(results)\n",
    "        r_arr.append([mean_predictions, lower_bounds, upper_bounds,difference])\n",
    "        RF_pred.append(RF_pred_E)\n",
    "    return RF_pred\n",
    "\n",
    "\n",
    "\n",
    "def ACCURACY(translated_episodes,HD_model,chunk,abs_d,path='Data/Pred'):\n",
    "    '''\n",
    "    size of translated_episodes is limited by the number of colors available for one plot\n",
    "    '''\n",
    "    # plt.figure(figsize=(20, 12))\n",
    "    results_Arr=[]\n",
    "    r_arr=[]\n",
    "    E=0\n",
    "    RF_pred=[]\n",
    "    # translated_episodes = translate_multiple_episodes_steps(episode,RL_model,translator,d,unique1)\n",
    "    # colors = ['red','blue','green','yellow','black','purple','orange','pink','brown','grey','cyan','magenta','lime','olive'\\\n",
    "    # ,'teal','navy','maroon','violet','turquoise','salmon','gold','coral','indigo','crimson','azure','beige','chocolate',\\\n",
    "    # 'lavender','plum','orchid','tan','khaki','wheat','silver','sienna','peru','peachpuff','papayawhip','mistyrose','moccasin','lemonchiffon','lawngreen','lightgreen','limegreen']\n",
    "    for translated_episode in tqdm(translated_episodes, desc=f'extracting risk for episodes'):\n",
    "        RF_pred_E=[]\n",
    "        E+=1\n",
    "        num_time_steps = len(translated_episode) # Number of time steps\n",
    "        num_trees = HD_model.n_estimators\n",
    "        predictions = np.zeros((num_time_steps, num_trees))\n",
    "        for j in range(len(translated_episode)):\n",
    "            RF_pred_E.append(HD_model.predict_proba(translated_episode[j])[0][1])\n",
    "            for i, tree in enumerate(HD_model.estimators_):\n",
    "                Risk = tree.predict_proba(translated_episode[j])[0][1]\n",
    "                predictions[j, i] = Risk\n",
    "        # Calculate the mean prediction for each time step\n",
    "        mean_predictions = np.mean(predictions, axis=1)\n",
    "            \n",
    "        # Calculate the standard deviation for each time step\n",
    "        std_predictions = np.std(predictions, axis=1)\n",
    "\n",
    "        # Calculate the lower and upper bounds for the confidence intervals\n",
    "        confidence_level = 0.95 # Change as needed\n",
    "        z_score = scipy.stats.norm.ppf((1 + confidence_level) / 2)\n",
    "        lower_bounds = mean_predictions - z_score * std_predictions / np.sqrt(num_trees)\n",
    "        upper_bounds = mean_predictions + z_score * std_predictions / np.sqrt(num_trees)\n",
    "        difference = upper_bounds - lower_bounds\n",
    "        # Store the results in a dataframe\n",
    "        results = pd.DataFrame({\n",
    "            'Mean prediction': mean_predictions,\n",
    "            'Lower bound': lower_bounds,\n",
    "            'Upper bound': upper_bounds\n",
    "        })\n",
    "        # Save the results to a file\n",
    "        results_Arr.append(results)\n",
    "        r_arr.append([mean_predictions, lower_bounds, upper_bounds,difference])\n",
    "        RF_pred.append(RF_pred_E)\n",
    "    return RF_pred\n",
    "\n",
    "\n",
    "def ACCURACY_LU(translated_episodes,HD_model,chunk,abs_d,path='Data/Pred'):\n",
    "    '''\n",
    "    size of translated_episodes is limited by the number of colors available for one plot\n",
    "    '''\n",
    "    # plt.figure(figsize=(20, 12))\n",
    "    results_Arr=[]\n",
    "    r_arr=[]\n",
    "    E=0\n",
    "    RF_pred=[]\n",
    "    LB = []\n",
    "    UB = []\n",
    "    # translated_episodes = translate_multiple_episodes_steps(episode,RL_model,translator,d,unique1)\n",
    "    # colors = ['red','blue','green','yellow','black','purple','orange','pink','brown','grey','cyan','magenta','lime','olive'\\\n",
    "    # ,'teal','navy','maroon','violet','turquoise','salmon','gold','coral','indigo','crimson','azure','beige','chocolate',\\\n",
    "    # 'lavender','plum','orchid','tan','khaki','wheat','silver','sienna','peru','peachpuff','papayawhip','mistyrose','moccasin','lemonchiffon','lawngreen','lightgreen','limegreen']\n",
    "    for translated_episode in tqdm(translated_episodes, desc=f'extracting risk for episodes'):\n",
    "        RF_pred_E=[]\n",
    "        E+=1\n",
    "        num_time_steps = len(translated_episode) # Number of time steps\n",
    "        num_trees = HD_model.n_estimators\n",
    "        predictions = np.zeros((num_time_steps, num_trees))\n",
    "        for j in range(len(translated_episode)):\n",
    "            RF_pred_E.append(HD_model.predict_proba(translated_episode[j])[0][1])\n",
    "            for i, tree in enumerate(HD_model.estimators_):\n",
    "                Risk = tree.predict_proba(translated_episode[j])[0][1]\n",
    "                predictions[j, i] = Risk\n",
    "        # Calculate the mean prediction for each time step\n",
    "        mean_predictions = np.mean(predictions, axis=1)\n",
    "            \n",
    "        # Calculate the standard deviation for each time step\n",
    "        std_predictions = np.std(predictions, axis=1)\n",
    "\n",
    "        # Calculate the lower and upper bounds for the confidence intervals\n",
    "        confidence_level = 0.95 # Change as needed\n",
    "        z_score = scipy.stats.norm.ppf((1 + confidence_level) / 2)\n",
    "        lower_bounds = mean_predictions - z_score * std_predictions / np.sqrt(num_trees)\n",
    "        upper_bounds = mean_predictions + z_score * std_predictions / np.sqrt(num_trees)\n",
    "        difference = upper_bounds - lower_bounds\n",
    "        # Store the results in a dataframe\n",
    "        results = pd.DataFrame({\n",
    "            'Mean prediction': mean_predictions,\n",
    "            'Lower bound': lower_bounds,\n",
    "            'Upper bound': upper_bounds\n",
    "        })\n",
    "        # Save the results to a file\n",
    "        results_Arr.append(results)\n",
    "        r_arr.append([mean_predictions, lower_bounds, upper_bounds,difference])\n",
    "        RF_pred.append(RF_pred_E)\n",
    "        LB.append(list(lower_bounds))\n",
    "        UB.append(list(upper_bounds))\n",
    "    return RF_pred , LB , UB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weighted_performance(Pred, FRT, T):\n",
    "    labels = []\n",
    "    for episode in FRT:\n",
    "        if is_functional_fault(episode):\n",
    "            labels.append([1.0 for i in range(len(episode)-1)])\n",
    "        else:\n",
    "            labels.append([0.0 for i in range(len(episode)-1)])\n",
    "    \n",
    "    accuracy = []\n",
    "    accuracy_w = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    max_len = max([len(i) for i in Pred])\n",
    "    for i in range(max_len):\n",
    "        pred_interval = [0 if pred[i]<=T else 1 for pred in Pred if len(pred)>i]\n",
    "        labels_interval = [label[i] for label in labels if len(label)>i]\n",
    "        accuracy.append(accuracy_score(labels_interval,pred_interval))\n",
    "        accuracy_w.append(balanced_accuracy_score(labels_interval, pred_interval))\n",
    "        precision.append(precision_score(labels_interval, pred_interval, average='weighted'))\n",
    "        recall.append(recall_score(labels_interval, pred_interval, average='weighted'))\n",
    "    #     f1.append(f1_score(labels_interval, pred_interval, average='weighted'))\n",
    "    # micro_f1 = f1_score(labels_interval, pred_interval, average='micro')\n",
    "    # macro_f1 = f1_score(labels_interval, pred_interval, average='macro')\n",
    "    return [accuracy,accuracy_w, precision, recall]\n",
    "\n",
    "def extract_weighted_performance_f1_fixed_length(Pred, FRT, T):\n",
    "    labels = []\n",
    "    max_len = max([len(i) for i in Pred])\n",
    "    for episode in FRT:\n",
    "        if is_functional_fault(episode):\n",
    "            labels.append([1.0 for i in range(max_len)])\n",
    "        else:\n",
    "            labels.append([0.0 for i in range(max_len)])\n",
    "    # print(max_len)\n",
    "    accuracy = []\n",
    "    accuracy_B = []\n",
    "    # accuracy_w = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    f1_m = []\n",
    "    for i in range(max_len):\n",
    "        # pred_interval = [0 if pred[i]<=T else 1 for pred in Pred if len(pred)>i]\n",
    "        pred_interval = []\n",
    "        for pred in Pred:\n",
    "            if len(pred)>i:\n",
    "                if pred[i]<T:\n",
    "                    pred_interval.append(0.0)\n",
    "                else:\n",
    "                    pred_interval.append(1.0)\n",
    "            else:\n",
    "                if pred[-1]<T:\n",
    "                    pred_interval.append(0.0)\n",
    "                else:\n",
    "                    pred_interval.append(1.0)\n",
    "        labels_interval = [label[i] for label in labels if len(label)>i]\n",
    "        accuracy.append(accuracy_score(labels_interval,pred_interval))\n",
    "        accuracy_B.append(balanced_accuracy_score(labels_interval, pred_interval))\n",
    "        f1.append(f1_score(labels_interval, pred_interval, average='weighted'))\n",
    "        f1_m.append(f1_score(labels_interval, pred_interval, average='macro'))\n",
    "        precision.append(precision_score(labels_interval, pred_interval, average='weighted'))\n",
    "        recall.append(recall_score(labels_interval, pred_interval, average='weighted'))\n",
    "    return [accuracy,accuracy_B, precision, recall, f1, f1_m]\n",
    "\n",
    "def plot_and_save_metrics(metrics_w, save_path):\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(15, 10))\n",
    "    accuracy,accuracy_w, precision, recall, f1, f1_m = metrics_w\n",
    "    axs[0, 0].plot(accuracy)\n",
    "    axs[0, 0].set_title(\"Accuracy\")\n",
    "    axs[0, 1].plot(accuracy_w)\n",
    "    axs[0, 1].set_title(\"Balanced Accuracy\")\n",
    "    axs[1, 0].plot(precision)\n",
    "    axs[1, 0].set_title(\"Precision\")\n",
    "    axs[1, 1].plot(recall)\n",
    "    axs[1, 1].set_title(\"Recall\")\n",
    "    axs[2, 0].plot(f1)\n",
    "    axs[2, 0].set_title(\"F1_weighted\")\n",
    "    axs[2, 1].plot(f1_m)\n",
    "    axs[2, 1].set_title(\"F1_macro\")\n",
    "\n",
    "    plt.suptitle(\"Metrics Plot\")\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.93)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Dataset_path = \"Path to dataset\"\n",
    "\n",
    "Drive_model  =f\"{Dataset_path}/dqn-4-1-6-89946.zip\"\n",
    "\n",
    "mtc = gym.make('MountainCar-v0')\n",
    "mtc_wrapped = StoreAndTerminateWrapper(mtc)\n",
    "model = DQN('MlpPolicy',env=mtc_wrapped, verbose=1)\n",
    "model = model.load(Drive_model)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Abstraction level:  500 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "translating episodes: 100%|██████████| 200/200 [06:13<00:00,  1.87s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [06:24<00:00,  1.92s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [06:24<00:00,  1.92s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [06:38<00:00,  1.99s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [06:39<00:00,  2.00s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [05:52<00:00,  1.76s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [06:07<00:00,  1.84s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [06:00<00:00,  1.80s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [06:01<00:00,  1.81s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [05:56<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Abstraction level:  100 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "translating episodes: 100%|██████████| 200/200 [07:21<00:00,  2.21s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [07:39<00:00,  2.30s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [07:38<00:00,  2.29s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [07:40<00:00,  2.30s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [07:33<00:00,  2.27s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [06:07<00:00,  1.84s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [06:05<00:00,  1.83s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [06:08<00:00,  1.84s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [06:12<00:00,  1.86s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [06:01<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Abstraction level:  50 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "translating episodes: 100%|██████████| 200/200 [07:47<00:00,  2.34s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [07:48<00:00,  2.34s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [07:41<00:00,  2.31s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [08:00<00:00,  2.40s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [07:54<00:00,  2.37s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [05:53<00:00,  1.77s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [06:02<00:00,  1.81s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [06:07<00:00,  1.84s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [06:14<00:00,  1.87s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [06:12<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Abstraction level:  10 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "translating episodes: 100%|██████████| 200/200 [12:50<00:00,  3.85s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [12:52<00:00,  3.86s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [12:34<00:00,  3.77s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [12:44<00:00,  3.82s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [12:42<00:00,  3.81s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [08:24<00:00,  2.52s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [08:25<00:00,  2.53s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [08:24<00:00,  2.52s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [08:43<00:00,  2.62s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [08:20<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Abstraction level:  5 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "translating episodes: 100%|██████████| 200/200 [17:04<00:00,  5.12s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [17:12<00:00,  5.16s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [17:06<00:00,  5.13s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [16:53<00:00,  5.07s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [16:40<00:00,  5.00s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [13:18<00:00,  3.99s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [12:49<00:00,  3.85s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [13:12<00:00,  3.96s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [13:10<00:00,  3.95s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [13:06<00:00,  3.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Abstraction level:  1 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "translating episodes: 100%|██████████| 200/200 [43:58<00:00, 13.19s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [44:44<00:00, 13.42s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [44:08<00:00, 13.24s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [45:33<00:00, 13.67s/it]\n",
      "translating episodes: 100%|██████████| 200/200 [47:43<00:00, 14.32s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [10:47<00:00,  3.24s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [12:03<00:00,  3.62s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [13:19<00:00,  4.00s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [13:49<00:00,  4.15s/it]\n",
      "extracting risk for episodes: 100%|██████████| 200/200 [13:09<00:00,  3.95s/it]\n"
     ]
    }
   ],
   "source": [
    "######################################################### Read abstract classes #############\n",
    "# data of abstract classes\n",
    "d_set=[500,100,50,10,5,1]\n",
    "from tqdm import tqdm\n",
    "\n",
    "#read FRT and FRTS from pickle\n",
    "with open(f'{Dataset_path}/Random_episodes/FRT.pickle', 'rb') as file2:\n",
    "    FRT = pickle.load(file2)\n",
    "FRT = FRT[:1000]\n",
    "for d in d_set:\n",
    "    print('\\n Abstraction level: ',d,'\\n\\n')\n",
    "\n",
    "    Read_from_data = True\n",
    "    if Read_from_data:\n",
    "        with open(f'{Dataset_path}/Abstraction/Abstraction_data_sampled_200_{d}.pickle', 'rb') as file2:\n",
    "            unique1 = pickle.load(file2)\n",
    "        uni1=np.array(unique1)\n",
    "    else:\n",
    "        assert False , 'No training data'\n",
    "        unique1,uni1 = Abstract_classes(final_episodes,d,model)\n",
    "\n",
    "\n",
    "    #read model from pickle\n",
    "    with open(f'{Dataset_path}/ML_models/RF_FF_1rep_{d}.pickle', 'rb') as file2:\n",
    "        RF_FF_1rep = pickle.load(file2)\n",
    "\n",
    "    #########################################################  Plot Risk and Position #############\n",
    "    newpath = f'Data/Abs_{d}'\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "\n",
    "\n",
    "    #########################################################  save episodes #############\n",
    "    chunk_size = 200\n",
    "    start = 0\n",
    "    end = chunk_size\n",
    "    while start < len(FRT):\n",
    "        episode_chunk = translate_multiple_episodes_steps_tqdm(FRT[start:end], model, translator, d, unique1)\n",
    "        with open(f'{newpath}/episode_chunk_{start}_{end}.pickle', 'wb') as file2:\n",
    "            pickle.dump(episode_chunk, file2)\n",
    "        del episode_chunk\n",
    "        start += chunk_size\n",
    "        end += chunk_size\n",
    "        if end > len(FRT):\n",
    "            end = len(FRT)\n",
    "\n",
    "    #########################################################  plot accuracy #############\n",
    "    Pred = []\n",
    "    LB = []\n",
    "    UB = []\n",
    "    chunk_size = 200\n",
    "    start = 0\n",
    "    end = chunk_size\n",
    "    while start < len(FRT):\n",
    "        #read episodes from pickle\n",
    "        with open(f'{newpath}/episode_chunk_{start}_{end}.pickle', 'rb') as file2:\n",
    "            episode_chunk = pickle.load(file2)\n",
    "        prediction, lowerBound, UpperBound = ACCURACY_LU(episode_chunk,RF_FF_1rep,50,abs_d=d,path=newpath)\n",
    "        Pred += prediction\n",
    "        LB += lowerBound\n",
    "        UB += UpperBound\n",
    "        del episode_chunk\n",
    "        start += chunk_size\n",
    "        end += chunk_size\n",
    "        if end > len(FRT):\n",
    "            end = len(FRT)\n",
    "\n",
    "    with open(f'{newpath}/Pred.pickle', 'wb') as file2:\n",
    "        pickle.dump(Pred, file2)\n",
    "    with open(f'{newpath}/LB.pickle', 'wb') as file2:\n",
    "        pickle.dump(LB, file2)\n",
    "    with open(f'{newpath}/UB.pickle', 'wb') as file2:\n",
    "        pickle.dump(UB, file2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_and_save_metrics_in_one_plot(metrics_Low,metrics_AVG,metrics_high, save_path, meta_data):\n",
    "    # fig, axs = plt.subplots(3, 2, figsize=(15, 10))\n",
    "    keys = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1_weighted', 'f1_macro']\n",
    "    metric_low_dict = dict(zip(keys, metrics_Low))\n",
    "    metric_avg_dict = dict(zip(keys, metrics_AVG))\n",
    "    metric_high_dict = dict(zip(keys, metrics_high))\n",
    "\n",
    "\n",
    "    #create figure\n",
    "    figure = plt.figure(figsize=(8, 4))\n",
    "    #map x axis from [0,1] to [0,100] percents\n",
    "    # x = np.linspace(0, 1, len(metric_avg_dict['accuracy'])) * 100\n",
    "    \n",
    "    #plot metrics\n",
    "    plt.plot(metric_avg_dict['precision'], label='Precision')\n",
    "    plt.plot(metric_avg_dict['recall'], label='Recall')\n",
    "    # figure.plot(metric_avg_dict['f1_weighted'], label='F1_weighted')\n",
    "    plt.plot(metric_avg_dict['f1_macro'], label='F1-score')\n",
    "    # plt.set_title(\"Metrics Plot\")\n",
    "    #fix y axis to [0,1]\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f\"Performance Metrics Plot\")\n",
    "    # fix legends position to lower right\n",
    "    plt.legend(loc='lower right')\n",
    "    # plt.legend()\n",
    "\n",
    "    # plt.suptitle(\"Metrics Plot\")\n",
    "    plt.tight_layout()\n",
    "    # plt.subplots_adjust(top=0.93)\n",
    "    plt.savefig(save_path,metadata=meta_data)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot performance metrics for the optimal abstraction level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 5\n",
    "meta_data = {'Author': 'Unknown', 'Project': 'HD', 'Version': '1',\n",
    "                 'Description': 'D = Metrics in one graph metrics generated by function plot_combine_in _one .. Cartpole from UB, LB, AVG pickle files(v1)'}\n",
    "# load Pred, LB, UB from pickle\n",
    "newpath = f'Data/Episodes3/Abs_{d}'\n",
    "with open(f'{newpath}/Pred.pickle', 'rb') as file2:\n",
    "    Pred = pickle.load(file2)\n",
    "with open(f'{newpath}/LB.pickle', 'rb') as file2:\n",
    "    LB = pickle.load(file2)\n",
    "with open(f'{newpath}/UB.pickle', 'rb') as file2:\n",
    "    UB = pickle.load(file2)\n",
    "\n",
    "metric_A = extract_weighted_performance_f1_fixed_length(Pred, FRT, 0.5)\n",
    "metric_LB = extract_weighted_performance_f1_fixed_length(LB, FRT, 0.5)\n",
    "metric_UB = extract_weighted_performance_f1_fixed_length(UB, FRT, 0.5)\n",
    "# plot_and_save_metrics_combined(metric_LB,metric_A,metric_UB,f'MC_RQ/CI/MC_D5_{d}_metrics_combined_V1.png',meta_data)\n",
    "\n",
    "\n",
    "plot_and_save_metrics_in_one_plot(metric_LB,metric_A,metric_UB, f'MC_RQ/CI/MC_D5_{d}_metrics_combined_V1.png', meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to try other abstraction levels\n",
    "def plot_combined_v1(d,save_path,meta_data):\n",
    "    # load Pred, LB, UB from pickle\n",
    "    newpath = f'Data/Episodes3/Abs_{d}'\n",
    "    with open(f'{newpath}/Pred.pickle', 'rb') as file2:\n",
    "        Pred = pickle.load(file2)\n",
    "    with open(f'{newpath}/LB.pickle', 'rb') as file2:\n",
    "        LB = pickle.load(file2)\n",
    "    with open(f'{newpath}/UB.pickle', 'rb') as file2:\n",
    "        UB = pickle.load(file2)\n",
    "\n",
    "    metric_A = extract_weighted_performance_f1_fixed_length(Pred, FRT, 0.5)\n",
    "    metric_LB = extract_weighted_performance_f1_fixed_length(LB, FRT, 0.5)\n",
    "    metric_UB = extract_weighted_performance_f1_fixed_length(UB, FRT, 0.5)\n",
    "    plot_and_save_metrics_combined(metric_LB,metric_A,metric_UB,save_path,meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_set=[500,100,50,10,5,1]\n",
    "\n",
    "for d in d_set:\n",
    "    Meta_Data = {'Author': 'Unknown', 'Project': 'HD', 'Version': '1',\n",
    "                 'Description': 'D = Metrics Combined metrics generated by function plot_combined_v1 Cartpole from UB, LB, AVG pickle files(v1)'}\n",
    "    plot_combined_v1(d, f'MC_RQ/CI/Cartpole_D_{d}_metrics_combined_V1.png', Meta_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_metrics_combined(metrics_Low,metrics_AVG,metrics_high, save_path, meta_data):\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(15, 10))\n",
    "    keys = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1_weighted', 'f1_macro']\n",
    "    metric_low_dict = dict(zip(keys, metrics_Low))\n",
    "    metric_avg_dict = dict(zip(keys, metrics_AVG))\n",
    "    metric_high_dict = dict(zip(keys, metrics_high))\n",
    "\n",
    "    axs[0, 0].plot(metric_low_dict['accuracy'], label='Lower Bound')\n",
    "    axs[0, 0].plot(metric_avg_dict['accuracy'], label='Average')\n",
    "    axs[0, 0].plot(metric_high_dict['accuracy'], label='Upper Bound')\n",
    "    axs[0, 0].set_title(\"Accuracy\")\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    axs[0, 1].plot(metric_low_dict['balanced_accuracy'], label='Lower Bound')\n",
    "    axs[0, 1].plot(metric_avg_dict['balanced_accuracy'], label='Average')\n",
    "    axs[0, 1].plot(metric_high_dict['balanced_accuracy'], label='Upper Bound')\n",
    "    axs[0, 1].set_title(\"Balanced Accuracy\")\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    axs[1, 0].plot(metric_low_dict['precision'], label='Lower Bound')\n",
    "    axs[1, 0].plot(metric_avg_dict['precision'], label='Average')\n",
    "    axs[1, 0].plot(metric_high_dict['precision'], label='Upper Bound')\n",
    "    axs[1, 0].set_title(\"Precision\")\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    axs[1, 1].plot(metric_low_dict['recall'], label='Lower Bound')\n",
    "    axs[1, 1].plot(metric_avg_dict['recall'], label='Average')\n",
    "    axs[1, 1].plot(metric_high_dict['recall'], label='Upper Bound')\n",
    "    axs[1, 1].set_title(\"Recall\")\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    axs[2, 0].plot(metric_low_dict['f1_weighted'], label='Lower Bound')\n",
    "    axs[2, 0].plot(metric_avg_dict['f1_weighted'], label='Average')\n",
    "    axs[2, 0].plot(metric_high_dict['f1_weighted'], label='Upper Bound')\n",
    "    axs[2, 0].set_title(\"F1_weighted\")\n",
    "    axs[2, 0].legend()\n",
    "\n",
    "    axs[2, 1].plot(metric_low_dict['f1_macro'], label='Lower Bound')\n",
    "    axs[2, 1].plot(metric_avg_dict['f1_macro'], label='Average')\n",
    "    axs[2, 1].plot(metric_high_dict['f1_macro'], label='Upper Bound')\n",
    "    axs[2, 1].set_title(\"F1_macro\")\n",
    "    axs[2, 1].legend()\n",
    "\n",
    "\n",
    "    plt.suptitle(\"Metrics Plot\")\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.93)\n",
    "    plt.savefig(save_path,metadata=meta_data)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_and_save_metrics_for_paper(metrics_Low,metrics_AVG,metrics_high, save_path, meta_data):\n",
    "    # fig, axs = plt.subplots(3, 2, figsize=(15, 10))\n",
    "    keys = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1_weighted', 'f1_macro']\n",
    "    metric_low_dict = dict(zip(keys, metrics_Low))\n",
    "    metric_avg_dict = dict(zip(keys, metrics_AVG))\n",
    "    metric_high_dict = dict(zip(keys, metrics_high))\n",
    "\n",
    "\n",
    "    figure = plt.figure(figsize=(8, 4))\n",
    "    #map x axis from [0,1] to [0,100] percents\n",
    "    # x = np.linspace(0, 1, len(metric_avg_dict['accuracy'])) * 100\n",
    "    \n",
    "    #plot metrics\n",
    "    plt.plot(metric_low_dict['f1_macro'], label='Lower Bound')\n",
    "    plt.plot(metric_avg_dict['f1_macro'], label='Average')\n",
    "    # figure.plot(metric_avg_dict['f1_weighted'], label='F1_weighted')\n",
    "    plt.plot(metric_high_dict['f1_macro'], label='Upper Bound')\n",
    "    # plt.set_title(\"Metrics Plot\")\n",
    "    #fix y axis to [0,1]\n",
    "    plt.ylim(0, 1.01)\n",
    "    plt.title(f\"F1-score\")\n",
    "    # fix legends position to lower right\n",
    "    plt.legend(loc='lower right')\n",
    "    # plt.legend()\n",
    "    # plt.suptitle(\"Metrics Plot\")\n",
    "    plt.tight_layout()\n",
    "    # plt.subplots_adjust(top=0.93)\n",
    "    plt.savefig(save_path,metadata=meta_data)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigerring criteria analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d=5 # best abstraction level # to reproduce the results of the paper use d=5    \n",
    "\n",
    "# load Pred, LB, UB from pickle\n",
    "newpath = f'Data/Episodes3/Abs_{d}'\n",
    "with open(f'{newpath}/Pred.pickle', 'rb') as file2:\n",
    "    Pred = pickle.load(file2)\n",
    "with open(f'{newpath}/LB.pickle', 'rb') as file2:\n",
    "    LB = pickle.load(file2)\n",
    "with open(f'{newpath}/UB.pickle', 'rb') as file2:\n",
    "    UB = pickle.load(file2)\n",
    "\n",
    "metric_A = extract_weighted_performance_f1_fixed_length(Pred, FRT, 0.5)\n",
    "#plot metrics and save them\n",
    "# plot_and_save_metrics(met, f'{newpath}/metrics_with_average_fixedL.png')\n",
    "\n",
    "#metrics based on lower bound\n",
    "metric_LB = extract_weighted_performance_f1_fixed_length(LB, FRT, 0.5)\n",
    "#plot metrics and save them\n",
    "# plot_and_save_metrics(metric2, f'{newpath}/metrics_with_lowerBound_fixedL.png')\n",
    "\n",
    "#metrics based on upper bound\n",
    "metric_UB = extract_weighted_performance_f1_fixed_length(UB, FRT, 0.5)\n",
    "#plot metrics and save them\n",
    "\n",
    "Meta_Data = {'Author': 'Unknown', 'Project': 'HD', 'Version': '1',\n",
    "              'Description': 'Metrics Combined metrics generated by function plot_and_save_metrics_combined Cartpole from UB, LB, AVG pickle files(v1)'}\n",
    "plot_and_save_metrics_combined(metric_LB,metric_A,metric_UB, f'MC_RQ/Cartpole_D_{d}_metrics_combined_V1.png', Meta_Data)\n",
    "plot_and_save_metrics_for_paper(metric_LB,metric_A,metric_UB, f'MC_RQ/Cartpole_D_{d}_metrics_combined_Vn2.png', Meta_Data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_metrics_for_dset(d_set, save_path, meta_data):\n",
    "    '''plots and saves metrics for a set of d values\n",
    "    this function is used to plot and save 3 files for lower bound, average and upper bound\n",
    "    in each file we have 6 plots for 6 metrics\n",
    "    and for each metric we have 11 lines for 11 d values'''\n",
    "    keys = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1_weighted', 'f1_macro']\n",
    "    Metric_data_dict = {}\n",
    "    for d in d_set:\n",
    "        with open(f'Data/Episodes3/Abs_{d}/Pred.pickle', 'rb') as file2:\n",
    "            Pred = pickle.load(file2)\n",
    "        with open(f'Data/Episodes3/Abs_{d}/LB.pickle', 'rb') as file2:\n",
    "            LB = pickle.load(file2)\n",
    "        with open(f'Data/Episodes3/Abs_{d}/UB.pickle', 'rb') as file2:\n",
    "            UB = pickle.load(file2)     \n",
    "\n",
    "        metrics_AVG = extract_weighted_performance_f1_fixed_length(Pred, FRT, 0.5)\n",
    "        metrics_Low = extract_weighted_performance_f1_fixed_length(LB, FRT, 0.5)\n",
    "        metrics_high = extract_weighted_performance_f1_fixed_length(UB, FRT, 0.5)\n",
    "        metric_low_dict = dict(zip(keys, metrics_Low))\n",
    "        metric_avg_dict = dict(zip(keys, metrics_AVG))\n",
    "        metric_high_dict = dict(zip(keys, metrics_high))\n",
    "        Metric_data_dict[f'Lower_Bound_{d}'] = metric_low_dict\n",
    "        Metric_data_dict[f'Average_{d}'] = metric_avg_dict\n",
    "        Metric_data_dict[f'Upper_Bound_{d}'] = metric_high_dict\n",
    "    \n",
    "    fig1, axs = plt.subplots(3, 2, figsize=(15, 10))\n",
    "    for d in d_set:\n",
    "        axs[0, 0].plot(Metric_data_dict[f'Lower_Bound_{d}']['accuracy'], label=f'd={d}')\n",
    "        axs[0, 1].plot(Metric_data_dict[f'Lower_Bound_{d}']['balanced_accuracy'], label=f'd={d}')\n",
    "        axs[1, 0].plot(Metric_data_dict[f'Lower_Bound_{d}']['precision'], label=f'd={d}')\n",
    "        axs[1, 1].plot(Metric_data_dict[f'Lower_Bound_{d}']['recall'], label=f'd={d}')\n",
    "        axs[2, 0].plot(Metric_data_dict[f'Lower_Bound_{d}']['f1_weighted'], label=f'd={d}')\n",
    "        axs[2, 1].plot(Metric_data_dict[f'Lower_Bound_{d}']['f1_macro'], label=f'd={d}')\n",
    "\n",
    "    axs[0, 0].set_title(\"Accuracy\")\n",
    "    axs[0, 1].set_title(\"Balanced Accuracy\")\n",
    "    axs[1, 0].set_title(\"Precision\")\n",
    "    axs[1, 1].set_title(\"Recall\")\n",
    "    axs[2, 0].set_title(\"F1 Weighted\")\n",
    "    axs[2, 1].set_title(\"F1 Macro\")\n",
    "    axs[0, 0].legend()\n",
    "    axs[0, 1].legend()\n",
    "    axs[1, 0].legend()\n",
    "    axs[1, 1].legend()\n",
    "    axs[2, 0].legend()\n",
    "    axs[2, 1].legend()\n",
    "    \n",
    "    plt.suptitle(\"Metrics Plot Lower Bound\")\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.93)\n",
    "    # plt.savefig(save_path,metadata=meta_data)\n",
    "    fig1.savefig(f'{save_path}/MountainCar_LB_abstraction_combined_V1.png', meta_data=meta_data)\n",
    "    plt.close()\n",
    "\n",
    "    fig2, axs = plt.subplots(3, 2, figsize=(15, 10))  \n",
    "    for d in d_set:\n",
    "        axs[0, 0].plot(Metric_data_dict[f'Average_{d}']['accuracy'], label=f'd={d}')\n",
    "        axs[0, 1].plot(Metric_data_dict[f'Average_{d}']['balanced_accuracy'], label=f'd={d}')\n",
    "        axs[1, 0].plot(Metric_data_dict[f'Average_{d}']['precision'], label=f'd={d}')\n",
    "        axs[1, 1].plot(Metric_data_dict[f'Average_{d}']['recall'], label=f'd={d}')\n",
    "        axs[2, 0].plot(Metric_data_dict[f'Average_{d}']['f1_weighted'], label=f'd={d}')\n",
    "        axs[2, 1].plot(Metric_data_dict[f'Average_{d}']['f1_macro'], label=f'd={d}')\n",
    "\n",
    "    axs[0, 0].set_title(\"Accuracy\")\n",
    "    axs[0, 1].set_title(\"Balanced Accuracy\")\n",
    "    axs[1, 0].set_title(\"Precision\")\n",
    "    axs[1, 1].set_title(\"Recall\")\n",
    "    axs[2, 0].set_title(\"F1 Weighted\")\n",
    "    axs[2, 1].set_title(\"F1 Macro\")\n",
    "    axs[0, 0].legend()\n",
    "    axs[0, 1].legend()\n",
    "    axs[1, 0].legend()\n",
    "    axs[1, 1].legend()\n",
    "    axs[2, 0].legend()\n",
    "    axs[2, 1].legend()\n",
    "    \n",
    "    plt.suptitle(\"Metrics Plot Average\")\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.93)\n",
    "    # plt.savefig(save_path,metadata=meta_data)\n",
    "    fig2.savefig(f'{save_path}/MountainCar_AVG_abstraction_combined_V1.png', meta_data=meta_data)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    fig3, axs = plt.subplots(3, 2, figsize=(15, 10))\n",
    "    for d in d_set:\n",
    "        axs[0, 0].plot(Metric_data_dict[f'Upper_Bound_{d}']['accuracy'], label=f'd={d}')\n",
    "        axs[0, 1].plot(Metric_data_dict[f'Upper_Bound_{d}']['balanced_accuracy'], label=f'd={d}')\n",
    "        axs[1, 0].plot(Metric_data_dict[f'Upper_Bound_{d}']['precision'], label=f'd={d}')\n",
    "        axs[1, 1].plot(Metric_data_dict[f'Upper_Bound_{d}']['recall'], label=f'd={d}')\n",
    "        axs[2, 0].plot(Metric_data_dict[f'Upper_Bound_{d}']['f1_weighted'], label=f'd={d}')\n",
    "        axs[2, 1].plot(Metric_data_dict[f'Upper_Bound_{d}']['f1_macro'], label=f'd={d}')\n",
    "\n",
    "    axs[0, 0].set_title(\"Accuracy\")\n",
    "    axs[0, 1].set_title(\"Balanced Accuracy\")\n",
    "    axs[1, 0].set_title(\"Precision\")\n",
    "    axs[1, 1].set_title(\"Recall\")\n",
    "    axs[2, 0].set_title(\"F1 Weighted\")\n",
    "    axs[2, 1].set_title(\"F1 Macro\")\n",
    "    axs[0, 0].legend()\n",
    "    axs[0, 1].legend()\n",
    "    axs[1, 0].legend()\n",
    "    axs[1, 1].legend()\n",
    "    axs[2, 0].legend()\n",
    "    axs[2, 1].legend()\n",
    "    \n",
    "    plt.suptitle(\"Metrics Plot Upper Bound\")\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.93)\n",
    "    plt.savefig(save_path,metadata=meta_data)\n",
    "    fig3.savefig(f'{save_path}/MountainCar_UB_abstraction_combined_V1.png', meta_data=meta_data)\n",
    "    plt.close()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstraction levels comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_set=[500,100,50,10,5,1]\n",
    "Meta_Data = {'Author': 'Unknown', 'Project': 'HD', 'Version': '1',\n",
    "                 'Description': 'D = Combined abstraction metrics generated by function plot_and_save_metrics_for_dset Cartpole from UB, LB, AVG pickle files(v1) 11 abstraction levels'}\n",
    "# EPSILON = 0.05\n",
    "with open(f'c:/Users/Student/Desktop/vs_git/HazardDetection/Data/Random_episodes/FRT.pickle', 'rb') as file2:\n",
    "    FRT = pickle.load(file2)\n",
    "FRT = FRT[:1000]\n",
    "len(FRT)\n",
    "\n",
    "plot_and_save_metrics_for_dset(d_set,f'MC_RQ/Abstraction',Meta_Data)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_portion(Pred, FRT, T):\n",
    "    labels = []\n",
    "    max_len = max([len(i) for i in Pred])\n",
    "    for episode in FRT:\n",
    "        if is_functional_fault(episode):\n",
    "            labels.append([1.0 for i in range(max_len)])\n",
    "        else:\n",
    "            labels.append([0.0 for i in range(max_len)])\n",
    "\n",
    "    prediction_timestep = []\n",
    "    prediction_probability = []\n",
    "    remaining_timesteps = []\n",
    "    remaining_portion = []\n",
    "\n",
    "    dict= {}\n",
    "\n",
    "    FP=0\n",
    "    FP_episodes_ID = []\n",
    "    \n",
    "    FP_info = {}\n",
    "\n",
    "    for i in range(len(Pred)):\n",
    "        for j in range(len(Pred[i])):\n",
    "            if Pred[i][j] >= T:   # if safety threshold is reached\n",
    "                if labels[i][j] == 1.0:  # if prediction was correct   \n",
    "                    prediction_timestep.append(j)   # add ratios to the dictionary\n",
    "                    prediction_probability.append(Pred[i][j])\n",
    "                    remaining_timesteps.append(len(Pred[i])-j-1)\n",
    "                    remaining_portion.append((len(Pred[i])-j-1)/len(Pred[i]))\n",
    "                    break\n",
    "                if labels[i][j] == 0.0: # if prediction was incorrect and we had a false positive\n",
    "                    prediction_timestep.append(None) # add None to the dictionary to indicate that there was a false positive\n",
    "                    prediction_probability.append(None)\n",
    "                    remaining_timesteps.append(None)\n",
    "                    remaining_portion.append(None)\n",
    "                    print(\"false positive\")\n",
    "                    FP+=1\n",
    "                    FP_episodes_ID.append(i)\n",
    "                    break\n",
    "            if j == len(Pred[i])-1:\n",
    "                prediction_timestep.append(None)\n",
    "                prediction_probability.append(None)\n",
    "                remaining_timesteps.append(None)\n",
    "                remaining_portion.append(None)\n",
    "    dict[\"prediction_timestep\"] = prediction_timestep\n",
    "    dict[\"prediction_probability\"] = prediction_probability\n",
    "    dict[\"remaining_timesteps\"] = remaining_timesteps\n",
    "    dict[\"remaining_portion\"] = remaining_portion\n",
    "\n",
    "    FP_info[\"Numbers\"] = FP\n",
    "    FP_info[\"FP_episodes_ID\"] = FP_episodes_ID\n",
    "    return dict, FP_info\n",
    "\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyze_portion_data(Dict_portion_data,Dict_FP_info):\n",
    "\n",
    "    prediction_timestep = [i for i in Dict_portion_data[\"prediction_timestep\"] if i is not None]\n",
    "    prediction_probability = [i for i in Dict_portion_data[\"prediction_probability\"] if i is not None]\n",
    "    remaining_timesteps = [i for i in Dict_portion_data[\"remaining_timesteps\"] if i is not None]\n",
    "    remaining_portion = [i for i in Dict_portion_data[\"remaining_portion\"] if i is not None]\n",
    "\n",
    "    print(\"mean prediction timestep: \", np.mean(prediction_timestep))\n",
    "    print(\"mean prediction probability: \", np.mean(prediction_probability))\n",
    "    print(\"mean remaining timesteps: \", np.mean(remaining_timesteps))\n",
    "    print(\"mean remaining portion: \", np.mean(remaining_portion))\n",
    "    print(\"\")\n",
    "    print(\"max prediction timestep: \", np.max(prediction_timestep))\n",
    "    print(\"max prediction probability: \", np.max(prediction_probability))\n",
    "    print(\"max remaining timesteps: \", np.max(remaining_timesteps))\n",
    "    print(\"max remaining portion: \", np.max(remaining_portion))\n",
    "    print(\"\")\n",
    "    print(\"min prediction timestep: \", np.min(prediction_timestep))\n",
    "    print(\"min prediction probability: \", np.min(prediction_probability))\n",
    "    print(\"min remaining timesteps: \", np.min(remaining_timesteps))\n",
    "    print(\"min remaining portion: \", np.min(remaining_portion))\n",
    "    print(\"\")\n",
    "    print(\"std prediction timestep: \", np.std(prediction_timestep))\n",
    "    print(\"std prediction probability: \", np.std(prediction_probability))\n",
    "    print(\"std remaining timesteps: \", np.std(remaining_timesteps))\n",
    "    print(\"std remaining portion: \", np.std(remaining_portion))\n",
    "    print(\"\")\n",
    "    print(\"number of false positives: \", Dict_FP_info[\"Numbers\"])\n",
    "    print(\"false positive episodes ID: \", Dict_FP_info[\"FP_episodes_ID\"])\n",
    "    print(\"number of true positives: \", len(prediction_timestep))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_correct_prediction_numbers(d):\n",
    "    # load Pred, LB, UB from pickle\n",
    "    newpath = f'Data/Episodes3/Abs_{d}'\n",
    "    with open(f'{newpath}/Pred.pickle', 'rb') as file2:\n",
    "        Pred = pickle.load(file2)\n",
    "    with open(f'{newpath}/LB.pickle', 'rb') as file2:\n",
    "        LB = pickle.load(file2)\n",
    "    with open(f'{newpath}/UB.pickle', 'rb') as file2:\n",
    "        UB = pickle.load(file2)\n",
    "\n",
    "    Dict_pred,FP_pred = extract_portion(Pred, FRT, 0.5)\n",
    "    Dict_LB,FP_LB = extract_portion(LB, FRT, 0.5)\n",
    "    Dict_UB, FP_UB = extract_portion(UB, FRT, 0.5)\n",
    "\n",
    "    print(\"#####################################  Results for Prediction #####################################\")\n",
    "    Analyze_portion_data(Dict_pred,FP_pred)\n",
    "    print(\"##################################### Results for Lower bound #####################################\")\n",
    "    Analyze_portion_data(Dict_LB,FP_LB)\n",
    "    print(\"##################################### Results for Upper bound #####################################\")\n",
    "    Analyze_portion_data(Dict_UB,FP_UB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1 analysis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "false positive\n",
      "false positive\n",
      "false positive\n",
      "false positive\n",
      "#####################################  Results for Prediction #####################################\n",
      "mean prediction timestep:  32.53030303030303\n",
      "mean prediction probability:  0.5049242424242424\n",
      "mean remaining timesteps:  62.65909090909091\n",
      "mean remaining portion:  0.6515408082452303\n",
      "\n",
      "max prediction timestep:  63\n",
      "max prediction probability:  0.55\n",
      "max remaining timesteps:  75\n",
      "max remaining portion:  0.78125\n",
      "\n",
      "min prediction timestep:  20\n",
      "min prediction probability:  0.5\n",
      "min remaining timesteps:  32\n",
      "min remaining portion:  0.3333333333333333\n",
      "\n",
      "std prediction timestep:  9.447975086837706\n",
      "std prediction probability:  0.008571995641305702\n",
      "std remaining timesteps:  9.324803633852959\n",
      "std remaining portion:  0.09785506055646193\n",
      "\n",
      "number of false positives:  1\n",
      "false positive episodes ID:  [239]\n",
      "number of true positives:  132\n",
      "##################################### Results for Lower bound #####################################\n",
      "mean prediction timestep:  44.39393939393939\n",
      "mean prediction probability:  0.5168914808257475\n",
      "mean remaining timesteps:  50.79545454545455\n",
      "mean remaining portion:  0.5281262417309284\n",
      "\n",
      "max prediction timestep:  76\n",
      "max prediction probability:  0.5671547869104842\n",
      "max remaining timesteps:  70\n",
      "max remaining portion:  0.7291666666666666\n",
      "\n",
      "min prediction timestep:  25\n",
      "min prediction probability:  0.5039817664728938\n",
      "min remaining timesteps:  19\n",
      "min remaining portion:  0.19791666666666666\n",
      "\n",
      "std prediction timestep:  8.49220460343661\n",
      "std prediction probability:  0.013469731329370873\n",
      "std remaining timesteps:  8.439390539142996\n",
      "std remaining portion:  0.08816461320830835\n",
      "\n",
      "number of false positives:  1\n",
      "false positive episodes ID:  [239]\n",
      "number of true positives:  132\n",
      "##################################### Results for Upper bound #####################################\n",
      "mean prediction timestep:  20.96969696969697\n",
      "mean prediction probability:  0.5135153650375471\n",
      "mean remaining timesteps:  74.21969696969697\n",
      "mean remaining portion:  0.7716189122642596\n",
      "\n",
      "max prediction timestep:  38\n",
      "max prediction probability:  0.5372900536241517\n",
      "max remaining timesteps:  80\n",
      "max remaining portion:  0.8333333333333334\n",
      "\n",
      "min prediction timestep:  15\n",
      "min prediction probability:  0.5063975564382162\n",
      "min remaining timesteps:  57\n",
      "min remaining portion:  0.59375\n",
      "\n",
      "std prediction timestep:  5.385079546891991\n",
      "std prediction probability:  0.008428807841296357\n",
      "std remaining timesteps:  5.360227259343488\n",
      "std remaining portion:  0.055954493497581324\n",
      "\n",
      "number of false positives:  2\n",
      "false positive episodes ID:  [239, 735]\n",
      "number of true positives:  132\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(f'c:/Users/Student/Desktop/vs_git/HazardDetection/Data/Random_episodes/FRT.pickle', 'rb') as file2:\n",
    "    FRT = pickle.load(file2)\n",
    "FRT = FRT[:1000]\n",
    "print(len(FRT))\n",
    "\n",
    "d_set = [5]\n",
    "for d in d_set:\n",
    "    extract_correct_prediction_numbers(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqS0lEQVR4nO3deXxU9bnH8c+TDRISEkJCErJAhIAEEraAUndFRVC5tlhRe62trfa2Vm2trUtrrb23dbu1vZUuaqutXVxotVSCgEqroihhS1hDICRA9pXs6+/+MZOYhIRMksmcWZ7365WXmTMncx6OM9/88pzfOUeMMSillPIuflYXoJRSyvk03JVSygtpuCullBfScFdKKS+k4a6UUl4owKoNR0VFmalTp1q1eaWU8kg7duyoMMZED7aeZeE+depUsrKyrNq8Ukp5JBEpcGQ9bcsopZQX0nBXSikvpOGulFJeSMNdKaW8kIa7Ukp5IQ13pZTyQhruSinlhSyb566UclxLewcvbD1GY0s7IsKqhQkkRoZYXZZyYxruSnmAzJxiHttwsPvx8apGfnbDPOsKUm5P2zJKeYD12SXEhY/l6E+W8/mMBDbvL6WlvcPqspQb03BXys2dam7jvdxyrpoTh5+fsDwtjrqWdt7PrbC6NOXGNNyVcnPvHCiltaOTFelxAJw3PYrw4EAyc4otrky5M4fCXUSWicghEckTkfv7ef5pEdlt/8oVkRqnV6qUj1qfXczk8LHMT4wAINDfjytnx2hrRp3RoOEuIv7AGuAqIBW4UURSe65jjPmWMWaeMWYe8Evg76NQq1I+x9aSqeCqNFtLpou2ZtRgHBm5LwbyjDFHjTGtwMvAyjOsfyPwV2cUp5Svy8wu7tWS6aKtGTUYR8I9Hjje4/EJ+7LTiMgUIBl4d4DnbxeRLBHJKi8vH2qtSvmUyvoWntx4iLT4cOYlRPR6LtDfj0VTI9lXdMqa4pTbc/YB1dXAWmNMv41AY8yzxpgMY0xGdPSgNxJRyqc9vG4fdc3tPHX93F4tmS5TJoZQWNWIMcaC6pS7cyTcTwKJPR4n2Jf1ZzXaklFqxDJzilmfXczdS1OYGRvW7zpJkSE0tXVQXt/i4uqUJ3Ak3LcDKSKSLCJB2AJ8Xd+VRORsYALwkXNLVMr3/N87hzk7Now7LjxrwHWS7JcfOF7V6KqylAcZNNyNMe3AncBG4ADwqjFmn4g8KiLX9lh1NfCy0b8RlRqRI+X1HCyp44ZFiQT4D/wRTZpoC/dCDXfVD4euLWOMyQQy+yx7uM/jR5xXllK+KzPbNgPmqjlxZ1wvPiIYESisbHJFWcrD6BmqSrmZ9TnFZEyZQGz42DOuNzbQn9jxY3Xkrvql4a6UG8krs7Vk+s5rH0hiZAiFVQ2jXJXyRBruSrmRrpOSBmvJdEmKDNGRu+qXXs9dKRf7x+6TnKhu4huXTAegtqmNe1/dzanmdnJL6xxqyXSZEhnC2lMtNLd1MDbQfzTLVh5GR+5KuZAxhqc2HeLpzblUN7QCttH62wfK6Ow0zIodzzcune7w63XNmDlRraN31ZuO3JVyoZyTtRyvss1u2bS/hBsWJZGZU8zUiSG89rUliJx+JuqZdN1qr7CqkemT+j/ZSfkmHbkr5ULrc4oJ8BPiwseyPqeEqoZWPjxSyfK0uCEHO3x6IlNBpY7cVW8a7kq5iDGG9dnFnDc9iv+YH8/WvApe2X6cjk7j8OyYviaOC2JckL8eVFWn0XBXykVyTtZyorqJFelxrEiLo6PT8PO3c5k6MYTUuPHDek0RITEyRC9BoE6jPXelXGR9tq0lc0VqDOHBgUyZGEJBZSMr0ofXkumSFBnC0YoG6prbupf5iTBujH68fZn+31fKRTbuK+G86VFEhAQBsCItjl/96wjL04bXkukyNWocm/aXkvbIpl7LH/tsGqsXJ43otZXn0nBXygXqW9o5VtnIqoUJ3cu+dvE05iVGMHty+Ihe+7bzk4kZP7bXdd3/tK2A13ac0HD3YRruSrlAXlk9QK/piuPHBnLF7NgRv3bM+LHcdn5yr2XNbR08tSmX4tom4sKDR7wN5Xn0gKpSLpBbWgfAjJhQl2yvq9WTmVPiku0p96PhrpQLHC6tIyjAjykTx7lke2dFhzIrbjzrs4tcsj3lfjTclXKBw2X1TIsOxb+fe6GOlqvT49hZWENRjV7v3RdpuCvlAodL613WkunyaWum2KXbVe5Bw12pUVbf0s7JmiZSJrk23JOjxpEWH84LW49R39Lu0m0r62m4KzXKDtsPpqbEuP7CXj+8JpWi2iYe23DA5dtW1tJwV2qUHbZPg5xhQbhnTI3ktvOS+dO2QrbmVWCMQe9h7xt0nrtSo+xwaR1jAvy6r+DoavdeMZN3DpZx8/MfA7aLjb102zmkTh7e9WyUZ9CRu1KjLLfU9TNlegoO8ucPX1rMty+fwT1LUxARvvPaHto6Oi2pR7mGhrtSo+xwaR0pLp4p01fSxBDuuiyFe5bO4CfXzWF/8SnWbMmztCY1urQto9Qoqm1qo6i22ZJ++0CumB3LynmTeebdPPLK6ntdkXJeYsRplzJQnsmhcBeRZcAvAH/geWPMY/2s83ngEcAAe4wxNzmxTqU80i/ePgzAZ6ZNtLiS3h65ZjaV9a3sLzrVvexUczuZOcVcNz+eyHFBFlannGHQcBcRf2ANcDlwAtguIuuMMft7rJMCPACcZ4ypFpFJo1WwUp7ik/wqXvgwny+cm8T8pAlWl9PLhHFB/Okr5/Ratq+olhX/9wEb95Vwo15N0uM50nNfDOQZY44aY1qBl4GVfdb5KrDGGFMNYIwpc26ZSnmWptYOvrt2D/ERwTxw1Syry3FIatx4kqPG6RmtXsKRcI8Hjvd4fMK+rKcZwAwR2Soi2+xtnNOIyO0ikiUiWeXl5cOrWCkP8MTGgxyrbOSJVekec0ckEWF5WiwfHqmkqqHV6nLUCDlrtkwAkAJcDNwIPCciEX1XMsY8a4zJMMZkREdHO2nTSrmXT/KrePHDY9yyZAqfmRZldTlDstx+b9eN+/RSwZ7OkXA/CST2eJxgX9bTCWCdMabNGJMP5GILe6V8SmNrO/et3UPChGC+t+xsq8sZsq7WzPpsbc14Okf+XtwOpIhIMrZQXw30nQnzBrYR+wsiEoWtTXPUiXUq5dbu/MtO3j1YRkenoaW9k79+9VyPacf01NWa+c2/j1JZ38LE0DFWl6SGadCRuzGmHbgT2AgcAF41xuwTkUdF5Fr7ahuBShHZD2wB7jPGVI5W0Uq5m/dyy5kWHcotS6aw5qYFLHGzqY9DsSJtsr01U2p1KWoEHBpaGGMygcw+yx7u8b0Bvm3/UsqnNLS0c6q5navSYvn6xdOtLmfEZsWFdc+auekcnRLpqfTyA0qNUHFtMwCTveRG1CLCirQ4PjxSQWV9i9XlqGHScFdqhIprbbexiw0fa3ElzrM8LY5Og7ZmPJiGu1Ij5G0jd7C1Zs6KGsf6HL3BtqfyvMP5SrmZ4hpbuMeEe8/MEtusmTh+9a88thwqY2yAf/dzyVHjvOqvFG+l4a7UCJWcaiIqNIgxPQLQG1wzdzLPbMnjSy9s77V8+qRQ3v72RRZVpRyl4a7UCBXVNHvlSHZmbBiZd11AbVNb97K39hbzh48KdA68B9BwV2qESmqbSZpozS30RlvfW/H5+wl/+KiAXYU1LE2Nsagq5Qg9oKrUCBXVNhHnhSP3/qQnhBPgJ+wsrLa6FDUIDXelRqC+pZ265nbivGimzJmMDfQndfJ4DXcPoOGu1AiU2Oe4+8rIHWBB0gT2HK+lXW+w7dY03JUaga457j4V7lMm0NTWwcGSOqtLUWeg4a7UCHTNcfeVtgzAgqQIAHZpa8atabgrNQJdI3dvOoFpMPERwUwKG8POwhqrS1FnoOGu1AgU13rnCUxnIiIsSJqgB1XdnIa7UiNQXNvsUy2ZLgunTKCgsrH7omnK/Wi4KzUCxbVNXnl26mAumzUJgA05eq9Vd6XhrtQIFNc2M9kHw/2s6FBmxY0nM0fvtequ9PIDSg1R9okaHnw9h4aWDuqa24n1wbYMwIq0WJ7alEtxbZNPtqbcnY7clRqC5rYO7nl5N6WnWpgTH85n58ezPC3W6rIssTwtDoBMbc24JR25KzUE/7vpEEcrGvjTbedwfkqU1eVYqmdr5rbzk60uR/Wh4a7UILbmVfBJfhXN7R08/0E+N52T5PPB3uXq9Die3HiIopomJkdoa8adaFtGqTNo7+jkrr/u4hfvHOa3/z7KrNjxPLh8ltVluY2u1syGvdqacTc6clfqDD7Or6KyoZVf37yAq+xBpj6VHDWO1LjxrM8u0taMm9GRu/JJdc1tdHSaQddbn1NMcKA/F8+c5IKqPNOK9Dh2FtZQVKMnNLkTDXflc45XNfKZx95lzZa8M67X3tHJxr0lXDZrEsFBvnN5gaH6dNaMznl3Jw6Fu4gsE5FDIpInIvf38/ytIlIuIrvtX19xfqlKjVxnp+G7a7Opa27n9V0nMWbg0XtXS2aFtmPOqKs1o+HuXgYNdxHxB9YAVwGpwI0iktrPqq8YY+bZv553cp1KOcWfPy7go6OVnJMcSX5FAweKB74m+fqcYkKCtCXjCG3NuB9HRu6LgTxjzFFjTCvwMrBydMtSynk+OlLJyjVbueaXH/Df6w9wQUoUv7p5Af5+wvqcon5/pqm1g417S7j0bG3JOKLrr5s3dp+0uBLVxZFwjweO93h8wr6sr8+JSLaIrBWRxP5eSERuF5EsEckqLy8fRrlKDd3vPsgnv7ye6LAxLJsTy5Or5jIxdAxLzppIZk5Jv62ZpzYdorKhlVuWTHV9wR5oatQ4LpwRzZp38zhe1Wh1OQrnHVD9JzDVGJMObAb+0N9KxphnjTEZxpiM6OhoJ21aqYHVNbfxXm45qxYm8vtbF/GL1fO7r+K4Ij2O/IoG9hef6vUzn+RX8fut+dyyZAqLkyOtKNsj/eS6OYgI9/89+4zHMpRrOBLuJ4GeI/EE+7JuxphKY0yL/eHzwELnlKfUyLx9oJTWjk5WpJ9+UPTK2bH4+wlPb87lufeOdn/dt3YPCROC+d6ysy2o2HMlTAjhweWz2JpXyZ8/LrS6HJ/nyElM24EUEUnGFuqrgZt6riAiccaYrkPl1wIHnFqlUsO0PruEuPCxzE+MOO25yHFBXD4rhrf2lfD2gbLu5SFB/vz+1kWMG6Pn+A3VjYsT+cfuk/zy3cPctDgJPz+xuiSfNei71xjTLiJ3AhsBf+D3xph9IvIokGWMWQfcJSLXAu1AFXDrKNaslENO2Vsy/7lkyoAh86ubF9DY1tFrWaC/+NRt85xJRLjpnCTufnk3OwuryZiqbS2rODQ0McZkApl9lj3c4/sHgAecW5pyB+0dnQAE+FtzvltNYyut7Z1nXCd0bAAhQZ++lZvbOjjV1Mam/baWzPIzzFP38xNCdYTuVJfNiiEowI83s4s13C2k72o1oM5Ow5de3E5reyev3LHE5dv/y8eFPPRGDoMdmwsbG8Df/+szpMSEUVnfwrXPbOWkfb715AFaMmr0hI4J4OIZ0WzYW8zDV6dqa8YiGu5qQC9tK+D9wxWA7ZT9xMgQl227oLKBH7+5n8VTI7l23uQB1zMGfrY5l++8toe//ddnePgf+yira+YHV6cyNtCPuQkRGi4WWJEex6b9peworGaRjt4toeGu+lVQ2cBjGw4yNyGcPSdqycwp5o6Lprlk252dhvvWZhPgL/x89bxBb+EWERLInX/ZxZf/kMV7ueXcd+VMvUKhxbpaM+uzizXcLaLhrk7THa5+wm/+cyF3vLSD9fZwLz3VzA//sY+aplb8RLjz0ul8ZprtxhUfHqngmXfz6Bygj3Ld/HhuWJQ06Pb/+NExPsmv4olV6Q7dm/Pq9Mlk5hSTmVNCekI4d1x41tD+wcrpQscEcMnMaNbuOMHBklNnXDdlUhg/vCbVsuM63kr3pjpNV7j+4OpU4sKDWZEWR/aJWgorG/ne37LZcqiMTgM5J2v59b+OdP/cr/91hJyTtXQaTvsqO9XCg6/vJftEzRm3XVDZwONvHeKSmdFcvzDB4Zp/vHIO1y9M4Okb5mlIuImvXnAWafHh/b4fur5a2jt5aVsBz72fb3W5XkesOpMsIyPDZGVlWbJtNbCCygaW/fx9zjkrkhduXYSIcLyqkQue2MK8xAh2H6/hkWtSufW8ZB7bcJDn3j9K1kNLAcj4n7f56gVncf9Vp5/8U9vUxpVPv8f44AD++c3z+51q2NlpWP3cNg4Un2Lzty7qPpNUeS9jDF//807eOVDG+rvOJyUmzOqS3J6I7DDGZAy2nrZlVLeeve6ffjYNEduByMTIEOYmhLP7eA3nJEd2X2/l6vQ4fvPvI2zaX4Ix0NFpuLqfM0EBwoMD+enn0vjSC9t54G85LOrntP6Dxaf4JL+KJ1ela7D7CBHh0ZVz2Hb0390HxfUvL+fQcFfddh2v5pP8Kv77P+ac1utetTCBoxUNPLEqvXv2yezJ40mKDOHNbNvJyUmRIcyePH7A179k5iS+cG4Sf9pWyN939X/1wGWzY1k1hHaM8nzRYWP44TWzueeV3bx7sIwrZsdaXZJX0HBX3XYUVAO2a6709YVzp3B9RiJjAz9tp4gIK9LjePa9owDcfuFZ3aP9gfx45RzuujSFge5wFzN+zKCvobzPivQ4HvnnPjJzijXcnUTDXXXbWVBDUmQI0WFjTntORHoFe5cVaXHdB1UduWORiDBpvLZcVG+B/n5cmRrL+pximts6+n2vqaHR5pYCbAe2dhZWsyApYkg/N3vyeKZMDGHKxDO3ZJQazIr0OOpb2nkvV+/14Aw6clcAnKxpoqyuhQVTJgzp50SENTct6P5eqeFaMm0iESGB2ppxEg13BcDOwhoAFiQNLdwB5sSHO7ka5YsC/f1YNjuWN7O1NeMMGu4KgJ0F1QQH+nN2rM4zVtZZnhbHy9uPc8vvPmF88KfxlDo5nG8tTdG/DodAw10BsKuwmvSEcJ1jrCy1ZNpELk+NoaimiYbWdsB2FuvbB8pIiAjm84v6vT2z6oeGu6K5rYN9Raf4ql6TRVks0N+P527pffJlZ6fhxue28eM393N+ShSTIwa/3pDS2TKW21VYzbo9RazbU0SR/Rrkw5FzopaW9o7BV+zvZ0/W0t5phtVvV2q0+fkJT66aS3un4d5X97BuTxEbcoppah3e+91X6MjdQo2t7dzw22202u92FB02hs3fupCIkKAhvc7b+0v5yh+zuG5+PE/fMG/Idfzl40IC/GTI0yCVcpWkiSE8tGIW339jLx8drQTgB1en6qWdz0BH7hbac7yW1o5OHv9cGn/48mKqG1p5ZN2+Ib1GTWMrD7yew9hAP17fdZLN+0uH9PNv7y/l9V0n+frF05gYevrJS0q5iy+cO4UP77+Ut799EfERwWQdq7K6JLem4W6hnYWfnu5/0Yxovn7JdN7YXcSmfSUOv8aP/rmf6oZWXr59CbPixvPg6znUNLY69LNdvxjOjg3jzktThvVvUMqVJkcEM31SKBlTJ7CzsBqrrmrrCbQtY6FdhdWcFT2uuw1z5yXT2by/lNtf2jGk17nrshTmJUbw1PXprHxmK/Me3QzA/KQI/vrVcwecL/yzzblUN7Tywq2LCArQ3/PKcyxImsA/dhdRVNtMvB5g7ZeGu0Vsp/vXcOnZk7qXBQX48fwXM1ibdYIOB0ckUaFBrLbf3Wj25HBe+NIith+rpqGlnd99kM/PNufy4PJZp/1cW0cn6/YUsSI9Tk9CUh6n6+D/zoJqDfcBaLhbpKCykaqGVub3OYgZHxHM3UuH3yK5ICWaC1KiAWhq6+C5949y5exYFva5rMCHRyqpaWzj6vSBbz6tlLs6Oy6MsYF+7Cys5pq5+h7uj/4tbpGufvtoTj98cPksJocHc99re2hu6z1tbH12EaFjArggJWrUtq/UaAn09yM9PqL7shnqdA6Fu4gsE5FDIpInIvefYb3PiYgRkUFvAeXrdhZWEzomgBmjeFux0DEBPLEqnaMVDTy18VD38raOTjbuK+Xy1Bi9fofyWPOnRLC/qPa0gYuyGTTcRcQfWANcBaQCN4pIaj/rhQF3Ax87u0hvtLOghrmJ4fj7je61Ms6bHsXN5yTxu6353VPHtuZVUNvUxnIHrr+ulLtakDSBtg7D3pO1VpfilhwZuS8G8owxR40xrcDLwMp+1vsx8DjQ7MT6vFJDSzsHS0657IzQB5bPIj4imPvWZvPOgVL+tK2QMG3JKA/XfVDV3uJUvTkS7vHA8R6PT9iXdRORBUCiMWb9mV5IRG4XkSwRySov990L8v9910k6DSyaevpNokdDV3umoLKB2/6QxdsHSlk2J1ZbMsqjRYeNYcrEED46Uml1KW5pxLNlRMQP+Blw62DrGmOeBZ4FyMjI8MmzD45XNfJY5gEuSIly6cj5M9OieO+7l1BZbzvBaTR7/Uq5yhWpMbz44TFqm9oIDw60uhy34sjI/STQ8zqbCfZlXcKAOcC/ROQYcC6wTg+qnq6z0/C9v2UjIjz2uXSXX5s6YUIIcxMjmJsYQXCQjtqV51uRPpm2DjPky274AkdG7tuBFBFJxhbqq4Gbup40xtQC3UNQEfkX8B1jTJZzS/VcT208xIsfHqPTGBpbO/jJdWl64oVSTjA3IZz4iGAyc4pZtTDB6nLcyqDhboxpF5E7gY2AP/B7Y8w+EXkUyDLGrBvtIj3dpv0lTBo/hktmTmLKxBBuXKw3HFDKGUSEFelxvLA1X1szfTjUczfGZAKZfZY9PMC6F4+8LO/R1tFJfkUDX7ngLL637Gyry1HK6yxPi+PZ946yeX+pjt570MsPjLKCygbaOgwpk0KtLkUpr9TVmvnVv/LYWVhNZEgQ9yxN8flbRvr2v94FckvrAZ2dotRoERFuOz+ZU03tbMgp5pkteXyQV2F1WZbTcB9luaV1iMC0aB25KzVavnx+MlnfX8pHD1xG6JgAMnOKrS7Jchruo+xwWT2JE0J06qFSLjA20J/LU2PYuK+UNvvtK32VhvsoO1xax4wYHbUr5SrL0+KobWpjq4+3ZjTcR1HXTJkU7bcr5TIXpERpawYN91HVNVNGR+5KuY62Zmw03EdR10yZlEk6clfKlbpaM+8c8N3LEmi4jyKdKaOUNS6aEU3KpFB+9M/9nGpus7ocS2i4j6LDpfUkRepMGaVcLSjAjyevn0vpqWb+580DVpdjCQ33UXS4rE5bMkpZZF5iBHdcNI1Xso7zXq7v3T9Cw32UlNe1kFdWz5z48VaXopTPuvuyFCaFjeGVrOODr+xlNNxHyVv7Sug0sGxOrNWlKOWzxgb6kxYfTp59coMv0XAfJZnZxUyLHsdMneOulKVSYsI4WlHvc9MiNdxHQVldMx/nV7IifbLL77aklOptRkwobR2GgsoGq0txKQ33UbBxr60lsyItzupSlPJ5XZMacn2sNaPhPgrW5xQzfVKonpmqlBuYPikUEdvUZF+iN+twwL6iWu59dY/DPbujFQ1889IUbcko5QaCg/xJnBBCblmd1aW4lIa7AzbklHC4rN7hmS9zEyK4aXHSKFellHLUjJhQDpdquKs+dhZWMysujDU3LbC6FKXUMEyfFMa/c8tp6+gk0Eduv+cb/8oR6Og07Dlew4KkCVaXopQaJl+cMaPhPohDJXU0tHZouCvlwbruYexLM2Y03Aexs7AaQMNdKQ82Ldo2YybXh/ruGu6D2FlYTVRoEImRwVaXopQapq4ZM4fLdOSu7HYV1jA/aYJOa1TKw82MDWN7fhUNLe1Wl+ISDoW7iCwTkUMikici9/fz/NdEJEdEdovIByKS6vxSXa+qoZX8igZtySjlBe648CzK61t4bMNBq0txiUHDXUT8gTXAVUAqcGM/4f0XY0yaMWYe8ATwM2cXaoVd3f32CGsLUUqNWMbUSL58XjIvbSvgw7wKq8sZdY6M3BcDecaYo8aYVuBlYGXPFYwxp3o8HAcY55Xoeo+/dZCVz3zAD97YS4CfkJ4QYXVJSikn+M4VM0mOGsd9a7Op9/L2jCPhHg/0vNL9CfuyXkTkGyJyBNvI/a7+XkhEbheRLBHJKi93zzujVNa38Ox7R2lq62BGbBjfvDRFb5OnlJcIDvLnyVXpFNU28dNM7779ntMOqBpj1hhjpgHfA74/wDrPGmMyjDEZ0dHRztq0U23cV0pHp+HpG+bx4pcWc/fSFKtLUko5UcbUSG47L5k/f1zIVi9uzzgS7ieBxB6PE+zLBvIy8B8jqMlSmTnFJEeNIzVOb4+nlLe6196e+a4Xt2ccCfftQIqIJItIELAaWNdzBRHpObxdARx2XomuU1nfwodHKlieFqtTH5XyYj3bMz/x0vbMoOFujGkH7gQ2AgeAV40x+0TkURG51r7anSKyT0R2A98GvjhaBY+mjftK6TSwXG+yoZTX62rP/OXjQj447H3tGTHGmoktGRkZJisry5JtD+Tm57dRVNPMu/depCN3pXxAc1sHy3/xPi3tnbxyx7mMCfAnclwQ/n7u+/kXkR3GmIzB1tMzVO1qG9v46EiltmSU8iFjA/158npbe+b8x7ew6H/e5nO//pDWds+/mbZez91u5/FqOg2cNy3K6lKUUi60cEokr9y+hEOldZSdauaX7+bxzJY8vn35DKtLGxENd7tdBdX4CcxNjLC6FKWUiy1OjmRxciQAJ6qb+NWWPK5IjWFOfLjFlQ2ftmXsdhbWMDN2POPG6O87pXzZD69JZcK4IL7z2h46Oz33ZHsNd2x3W9p9vEavIaOUIiIkiO8tO5uDJXXd93PwRBruwOGyOupb2vXqj0opAJbNiSUowI/1OcVWlzJsGu7AjgL71R+naLgrpSB0TAAXz4gmM6fYY1szGu7AzoIaIscFMXViiNWlKKXcxIr0OEpPtXhsa0bDHdt12xckRej8dqVUt8tmxRAU4Meb2Z7ZmvHpcG9u66CktpmjFQ3M1367UqqHrtbMhr3FNLS009zWYXVJQ+Kz8/5+90E+P35zf/djPZiqlOprRXocm/aXMvuHGxGB+66cydcvnm51WQ7x2XDfUVBFdNgYbjs/mbCxAZxjP4FBKaW6LE+Lo7apjcbWDj46Usn/bsrlgunRpCW4/8lNPhvuhVWNzJ48nq9dNM3qUpRSbirQ349blkwF4MbFSVzx9L/5zmt7WPfN8xgT4N53aPPZnnthZSNJkTo7RinlmPDgQH762TQOldax+tltfPWPWTy58aDbTpX0yXCvaWzlVHO7hrtSakguPTuGby2dQXNbJ/kVDazZcoSXthVYXVa/fLItU1jVCECihrtSaojuXprC3UtTMMbwpRe389iGg1w8M5opE8dZXVovPjly7wr3KXrSklJqmESEn342jQB/4b612W7XnvHpcE+coOGulBq+uPBgfnB1Kp/kV/HHj45ZXU4vPhnux6saiQoN0sv7KqVG7PqFCVwyM5rH3zpEQWWD1eV088lwL6hs1H67UsopbO2ZdLdrz/jk0LWwqpGFegVIpZSTxIaP5eGrU7lvbTbTHsqk51Wq5sSH8/Lt5xIS5Nq49blwb+vopKimievmx1tdilLKi6xamIDB1vbt0tTawe+25vP4hoP8aOUcl9bjc+FeVNNEp9FpkEop5xIRPp+ReNryDmN4Yesxls2JY8m0iS6rx+fCvXsapIa7UsoFvnvl2Ww5WMa3XtndHe6rFiZw3vSoUd2uQwdURWSZiBwSkTwRub+f578tIvtFJFtE3hGRKc4v1TkKKm3hnqRz3JVSLhAc5M/TN8wjIiSQHQXV7CiopqK+ZdS3O+jIXUT8gTXA5cAJYLuIrDPG7O+x2i4gwxjTKCL/BTwB3DAaBY/U8apGgvz9iAkba3UpSikfMT9pAm/dc6FLt+nIyH0xkGeMOWqMaQVeBlb2XMEYs8UY03UUYRuQ4NwynaewqpGEyGD8/PSuS0op7+VIuMcDx3s8PmFfNpDbgA39PSEit4tIlohklZeXO16lk9Q0tvJJfhXTokNdvm2llHIlp57EJCJfADKAJ/t73hjzrDEmwxiTER0d7cxNO+SRdfuobWrjnqUpLt+2Ukq5kiOzZU4CPef3JNiX9SIiS4GHgIuMMaN/tGCINu0r4Y3dRdx9WQqzJ7v/XVSUUmokHBm5bwdSRCRZRIKA1cC6niuIyHzgt8C1xpgy55c5Mu0dnXz/jb3MihvPNy7xjPsfKqXUSAwa7saYduBOYCNwAHjVGLNPRB4VkWvtqz0JhAKvichuEVk3wMtZ4lhlI2V1Ldx2fjJBAT55OR2llI9x6CQmY0wmkNln2cM9vl/q5Lqc6nBpHQAzY8IsrkQppVzDJ4axuaX1iMD0STpLRinlG3wj3MvqSJwQQnCQe9+tXCmlnMUnwj2vtJ4UHbUrpXyI14d7W0cnRyvqSdF+u1LKh3h9uBdUNtDWYZgRoyN3pZTv8Ppwzy2tB2CGjtyVUj7E68P9sH2mjF5PRinlS7w+3HWmjFLKF3l9uB8urdN+u1LK53h1uLd1dJJf0cD0SdpvV0r5Fq+6h+qHeRX8+/Cn14mvb27XmTJKKZ/kNeFujOG+tdmUnGomoMddliLHBbFoaqSFlSmllOt5TbjvPl7DyZom/vf6uXxuodve5U8ppVzCa3rumTnFBPoLS1NjrC5FKaUs5xXhbowhM6eEC1OiCQ8OtLocpZSynFeEe1dLZnlanNWlKKWUW/CKcF+fXUyQv5+2ZJRSys7jDqi+uv04z71/tNeyE9VNXJASpS0ZpZSy87hwjwgJJKXPvPUZsWF85fxkiypSSin343HhfsXsWK6YHWt1GUop5da8oueulFKqNw13pZTyQhruSinlhTTclVLKC2m4K6WUF9JwV0opL6ThrpRSXkjDXSmlvJAYY6zZsEg5UDDMH48CKpxYjitoza7haTV7Wr2gNbvKQDVPMcZED/bDloX7SIhIljEmw+o6hkJrdg1Pq9nT6gWt2VVGWrO2ZZRSygtpuCullBfy1HB/1uoChkFrdg1Pq9nT6gWt2VVGVLNH9tyVUkqdmaeO3JVSSp2BhrtSSnkhjwt3EVkmIodEJE9E7re6nr5EJFFEtojIfhHZJyJ325dHishmETls/+8Eq2vtS0T8RWSXiLxpf5wsIh/b9/UrIhJkdY09iUiEiKwVkYMickBElrj7fhaRb9nfF3tF5K8iMtbd9rOI/F5EykRkb49l/e5Xsfk/e+3ZIrLATep90v6+yBaR10UkosdzD9jrPSQiV7q63oFq7vHcvSJiRCTK/nhY+9ijwl1E/IE1wFVAKnCjiKRaW9Vp2oF7jTGpwLnAN+w13g+8Y4xJAd6xP3Y3dwMHejx+HHjaGDMdqAZus6Sqgf0CeMsYczYwF1vtbrufRSQeuAvIMMbMAfyB1bjffn4RWNZn2UD79Sogxf51O/BrF9XY04ucXu9mYI4xJh3IBR4AsH8WVwOz7T/zK3uuuNqLnF4zIpIIXAEU9lg8vH1sjPGYL2AJsLHH4weAB6yua5Ca/wFcDhwC4uzL4oBDVtfWp84EbB/aS4E3AcF2dlxAf/ve6i8gHMjHPimgx3K33c9APHAciMR2i8s3gSvdcT8DU4G9g+1X4LfAjf2tZ2W9fZ67Dviz/ftemQFsBJa4wz62L1uLbaByDIgayT72qJE7n344upywL3NLIjIVmA98DMQYY4rtT5UAMVbVNYCfA98FOu2PJwI1xph2+2N329fJQDnwgr2V9LyIjMON97Mx5iTwFLZRWTFQC+zAvfdzl4H2qyd8Jr8MbLB/77b1ishK4KQxZk+fp4ZVs6eFu8cQkVDgb8A9xphTPZ8ztl+/bjMHVUSuBsqMMTusrmUIAoAFwK+NMfOBBvq0YNxwP08AVmL7xTQZGEc/f5q7O3fbr2ciIg9ha5X+2epazkREQoAHgYed9ZqeFu4ngcQejxPsy9yKiARiC/Y/G2P+bl9cKiJx9ufjgDKr6uvHecC1InIMeBlba+YXQISIBNjXcbd9fQI4YYz52P54Lbawd+f9vBTIN8aUG2PagL9j2/fuvJ+7DLRf3fYzKSK3AlcDN9t/IYH71jsN2y/9PfbPYQKwU0RiGWbNnhbu24EU++yCIGwHRtZZXFMvIiLA74ADxpif9XhqHfBF+/dfxNaLdwvGmAeMMQnGmKnY9um7xpibgS3AKvtq7lZzCXBcRGbaF10G7MeN9zO2dsy5IhJif5901ey2+7mHgfbrOuAW+4yOc4HaHu0by4jIMmxtxmuNMY09nloHrBaRMSKSjO0g5SdW1NiTMSbHGDPJGDPV/jk8ASywv8+Ht4+tOJAwwoMQy7Ed/T4CPGR1Pf3Udz62P1mzgd32r+XYetjvAIeBt4FIq2sdoP6LgTft35+F7Y2fB7wGjLG6vj61zgOy7Pv6DWCCu+9n4EfAQWAv8BIwxt32M/BXbMcE2uwhc9tA+xXbgfc19s9jDraZQO5Qbx62PnXXZ/A3PdZ/yF7vIeAqd9nHfZ4/xqcHVIe1j/XyA0op5YU8rS2jlFLKARruSinlhTTclVLKC2m4K6WUF9JwV0opL6ThrpRSXkjDXSmlvND/A02KKsTItN4wAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#false positive episodes with oputput probability\n",
    "zz = [Pred[i] for i in FP_pred[\"FP_episodes_ID\"]]\n",
    "for cc in zz:\n",
    "    plt.plot(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# false positive episodes with upper bound\n",
    "zz = [UB[i] for i in FP_UB[\"FP_episodes_ID\"]]\n",
    "for cc in zz:\n",
    "    plt.plot(cc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
